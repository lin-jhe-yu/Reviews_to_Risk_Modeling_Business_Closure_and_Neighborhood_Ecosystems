{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "619421a5-94a5-4581-806a-40e0477a7bd8",
   "metadata": {},
   "source": [
    "## 1. Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0c97be6-8ed0-4bb8-be63-1aa107a90cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/12/01 18:18:11 WARN org.apache.spark.sql.catalyst.util.package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "[Stage 1:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+----------+--------------------+--------------------+--------------------+------------------+------------------+--------------------+--------------+-----+--------------------+-------------------+--------------------+---------------+--------------------+---------------+-----------------+--------------------+----------------------+-----------------+----------------------+---------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------+--------------------+-----+--------------+---------+---------------+------------------------+----------------+-------------+-----------------------+------------------+------------+\n",
      "|             gmap_id|             address|avg_rating|            category|         description|               hours|          latitude|         longitude|          store_name|num_of_reviews|price|    relative_results|              state|  MISC_Accessibility|MISC_Activities|      MISC_Amenities|MISC_Atmosphere|       MISC_Crowd| MISC_Dining_options|MISC_From_the_business|MISC_Getting_here|MISC_Health_and_safety|MISC_Highlights|MISC_Lodging_options|      MISC_Offerings|       MISC_Payments|       MISC_Planning|    MISC_Popular_for|MISC_Recycling|MISC_Service_options|  zip|      zip_city|zip_state|     zip_county|irs_estimated_population|permanent_closed|price_numeric|avg_predicted_sentiment|     sentiment_std|review_count|\n",
      "+--------------------+--------------------+----------+--------------------+--------------------+--------------------+------------------+------------------+--------------------+--------------+-----+--------------------+-------------------+--------------------+---------------+--------------------+---------------+-----------------+--------------------+----------------------+-----------------+----------------------+---------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------+--------------------+-----+--------------+---------+---------------+------------------------+----------------+-------------+-----------------------+------------------+------------+\n",
      "|0x89e85a90fa80ea7...|Checkers, 550 Wil...|       3.5|[Fast food restau...|Chain eatery serv...|[[Monday, 11AM–1A...|        40.7996343|-72.86699759999999|            Checkers|           426|    $|[0x89e85a90fe4fe4...|Closed ⋅ Opens 11AM|[Wheelchair acces...|           null|     [Good for kids]|       [Casual]|[Family-friendly]|[Breakfast, Lunch...|                  null|             null|                  null| [Fast service]|                null|[Kids' menu, Late...|[Debit cards, Cre...|                null|[Lunch, Dinner, S...|          null|[Outdoor seating,...|11967|       Shirley|       NY| Suffolk County|                   25560|               0|            1|     3.1702048057536985|1.0784551420278028|          11|\n",
      "|0x89c2c219189e518...|Momo Asian Fusion...|       4.6|[Japanese restaur...|                null|[[Friday, 11AM–9:...|41.121023199999996|       -73.9436054|   Momo Asian Fusion|            88| null|[0x89c2ea07be85c3...|Closed ⋅ Opens 11AM|[Wheelchair acces...|           null|[Good for kids, H...| [Casual, Cozy]|         [Groups]|           [Dessert]|                  null|             null|                  null|           null|                null|[Comfort food, He...|      [Credit cards]|[Accepts reservat...|[Lunch, Dinner, S...|          null|[Delivery, Takeou...|10989|Valley Cottage|       NY|Rockland County|                    8770|               0|            0|       4.58498825475099|0.5092351974776369|           5|\n",
      "|0x8085b6a8ebae49f...|Rosso Pizzeria & ...|       4.2|[Pizza restaurant...|Neapolitan pizza,...|[[Saturday, 11:30...|           38.2328|      -122.6372028|Rosso Pizzeria & ...|            78| null|[0x8085b41d6183b8...| Permanently closed|                null|           null|     [Good for kids]|           null|             null|                null|                  null|             null|                  null|           null|                null|                null|                null|                null|                null|          null|          [Delivery]|94952|      Petaluma|       CA|  Sonoma County|                   28770|               1|            0|      3.864661623144518|0.9601397247395762|           5|\n",
      "+--------------------+--------------------+----------+--------------------+--------------------+--------------------+------------------+------------------+--------------------+--------------+-----+--------------------+-------------------+--------------------+---------------+--------------------+---------------+-----------------+--------------------+----------------------+-----------------+----------------------+---------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------+--------------------+-----+--------------+---------+---------------+------------------------+----------------+-------------+-----------------------+------------------+------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "business_df = spark.read.parquet(\"gs://msca-bdp-student-gcs/Group_5_final_project/store_df/\")\n",
    "business_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b083390f-4bbe-47a2-8c54-a56ac9bb855b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:=================================================>       (14 + 2) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(business_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6301569-c5fa-44fd-b860-c21a956cbc79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------+-----------------------+------------+------------------+----------+\n",
      "|store_name                     |avg_predicted_sentiment|review_count|shrunk_sentiment  |avg_rating|\n",
      "+-------------------------------+-----------------------+------------+------------------+----------+\n",
      "|Checkers                       |3.1702048057536985     |11          |3.6295623775899735|3.5       |\n",
      "|Momo Asian Fusion              |4.58498825475099       |5           |4.28489988932358  |4.6       |\n",
      "|Rosso Pizzeria & Mozzarella Bar|3.864661623144518      |5           |4.044791012121423 |4.2       |\n",
      "|Junior's Restaurant & Bakery   |4.290628785509187      |15          |4.228319553949462 |4.4       |\n",
      "|Woori Village                  |3.1132834520223933     |10          |3.624069579316134 |3.5       |\n",
      "|The Flame Broiler              |4.007555898949703      |5           |4.092422437389818 |3.8       |\n",
      "|200 Fifth                      |4.116263523339339      |14          |4.124010266368729 |4.1       |\n",
      "|Wolffy's Grill and Marina      |4.237235247522416      |15          |4.1962834311574   |4.3       |\n",
      "|San Salvador Restaurant        |4.451223230894088      |15          |4.324676221180402 |4.3       |\n",
      "|La Herradura Inc II            |3.775857346585128      |5           |4.015189586601626 |4.1       |\n",
      "+-------------------------------+-----------------------+------------+------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# =========================\n",
    "# Parameters for shrinkage\n",
    "# =========================\n",
    "k = 10  # pseudo-count (adjust this to control shrinkage strength)\n",
    "\n",
    "# global mean of predicted sentiment across all stores\n",
    "global_mean = business_df.agg(F.mean(\"avg_predicted_sentiment\")).collect()[0][0]\n",
    "\n",
    "# =========================\n",
    "# Compute shrunk sentiment\n",
    "# =========================\n",
    "business_df = business_df.withColumn(\n",
    "    \"shrunk_sentiment\",\n",
    "    (F.col(\"avg_predicted_sentiment\") * F.col(\"review_count\") + global_mean * k) /\n",
    "    (F.col(\"review_count\") + k)\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# Show results\n",
    "# =========================\n",
    "business_df.select(\n",
    "    \"store_name\",\n",
    "    \"avg_predicted_sentiment\",\n",
    "    \"review_count\",\n",
    "    \"shrunk_sentiment\",\n",
    "    \"avg_rating\"\n",
    ").show(10, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5755afea-e36d-407b-8b24-d5446e1b6167",
   "metadata": {},
   "source": [
    "## 2. Checking missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac7b9948-a944-4809-8d7c-d293a86e5a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 13:=============================>                            (2 + 2) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+-------------+\n",
      "|column                  |missing_count|\n",
      "+------------------------+-------------+\n",
      "|gmap_id                 |0            |\n",
      "|address                 |0            |\n",
      "|avg_rating              |0            |\n",
      "|category                |0            |\n",
      "|description             |72284        |\n",
      "|hours                   |8333         |\n",
      "|latitude                |0            |\n",
      "|longitude               |0            |\n",
      "|store_name              |0            |\n",
      "|num_of_reviews          |0            |\n",
      "|price                   |47163        |\n",
      "|relative_results        |12725        |\n",
      "|state                   |46186        |\n",
      "|MISC_Accessibility      |33726        |\n",
      "|MISC_Activities         |169478       |\n",
      "|MISC_Amenities          |26983        |\n",
      "|MISC_Atmosphere         |38927        |\n",
      "|MISC_Crowd              |52454        |\n",
      "|MISC_Dining_options     |50973        |\n",
      "|MISC_From_the_business  |163447       |\n",
      "|MISC_Getting_here       |169478       |\n",
      "|MISC_Health_and_safety  |168116       |\n",
      "|MISC_Highlights         |91905        |\n",
      "|MISC_Lodging_options    |169478       |\n",
      "|MISC_Offerings          |25206        |\n",
      "|MISC_Payments           |74194        |\n",
      "|MISC_Planning           |117245       |\n",
      "|MISC_Popular_for        |44101        |\n",
      "|MISC_Recycling          |169477       |\n",
      "|MISC_Service_options    |3470         |\n",
      "|zip                     |0            |\n",
      "|zip_city                |0            |\n",
      "|zip_state               |0            |\n",
      "|zip_county              |0            |\n",
      "|irs_estimated_population|0            |\n",
      "|permanent_closed        |0            |\n",
      "|price_numeric           |0            |\n",
      "|avg_predicted_sentiment |0            |\n",
      "|sentiment_std           |0            |\n",
      "|review_count            |0            |\n",
      "|shrunk_sentiment        |0            |\n",
      "+------------------------+-------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, sum as spark_sum, lit\n",
    "from pyspark.sql import Row\n",
    "\n",
    "# Step 1: compute missing counts (one row)\n",
    "missing_df = business_df.select([\n",
    "    spark_sum(col(c).isNull().cast(\"int\")).alias(c)\n",
    "    for c in business_df.columns\n",
    "])\n",
    "\n",
    "# Step 2: collect as Python dict\n",
    "missing_dict = missing_df.first().asDict()\n",
    "\n",
    "# Step 3: convert to list of Rows\n",
    "rows = [Row(column=col_name, missing_count=missing_dict[col_name])\n",
    "        for col_name in missing_dict]\n",
    "\n",
    "# Step 4: create a transposed Spark DataFrame\n",
    "transposed_missing_df = spark.createDataFrame(rows)\n",
    "\n",
    "# Step 5: show results\n",
    "transposed_missing_df.show(50, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0537d322-2bf8-4c2a-9f10-eb6ee0e39110",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = [\n",
    "    \"MISC_Activities\", \"MISC_From_the_business\", \"MISC_Getting_here\",\n",
    "    \"MISC_Health_and_safety\", \"MISC_Lodging_options\", \"MISC_Recycling\"\n",
    "    \"review_count\", \n",
    "]\n",
    "\n",
    "business_df_clean = business_df.drop(*cols_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29f9bbf0-75f7-4cf4-be1d-d8d4f22a7e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import DoubleType\n",
    "\n",
    "business_df_clean = business_df_clean.withColumn(\"irs_estimated_population\", col(\"irs_estimated_population\").cast(DoubleType()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d90ec51-77fd-4469-999b-5433467e1568",
   "metadata": {},
   "source": [
    "#### One-hot encoding top 3 categories for each categorical column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eefe26db-6a0d-4c9f-93db-9722820f52f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import explode, col, when, array_contains\n",
    "\n",
    "misc_cols = [\n",
    "    \"MISC_Accessibility\", \"MISC_Amenities\", \"MISC_Atmosphere\",\n",
    "    \"MISC_Crowd\", \"MISC_Dining_options\", \"MISC_Offerings\",\n",
    "    \"MISC_Payments\", \"MISC_Planning\", \"MISC_Popular_for\",\n",
    "    \"MISC_Service_options\", \"MISC_Highlights\"\n",
    "]\n",
    "\n",
    "for c in misc_cols:\n",
    "    # Explode the array to count frequency\n",
    "    top_items = (business_df_clean\n",
    "                 .select(explode(col(c)).alias(\"item\"))\n",
    "                 .groupBy(\"item\")\n",
    "                 .count()\n",
    "                 .orderBy(col(\"count\").desc())\n",
    "                 .limit(3)\n",
    "                 .collect())\n",
    "    \n",
    "    top_items_list = [row[\"item\"] for row in top_items if row[\"item\"] is not None]\n",
    "\n",
    "    # Create one-hot columns for top 3\n",
    "    for item in top_items_list:\n",
    "        col_name = f\"{c}_{item.replace(' ', '_')}_flag\"\n",
    "        business_df_clean = business_df_clean.withColumn(\n",
    "            col_name,\n",
    "            when(array_contains(col(c), item), 1).otherwise(0)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be3a072e-26c9-4185-8cfb-7425c6611e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+----------+--------------------+--------------------+--------------------+------------------+------------------+--------------------+--------------+-----+--------------------+-------------------+--------------------+--------------------+---------------+-----------------+--------------------+---------------+--------------------+--------------------+--------------------+--------------------+--------------+--------------------+-----+--------------+---------+---------------+------------------------+----------------+-------------+-----------------------+------------------+------------+------------------+------------------------------------------------------+------------------------------------------------------+---------------------------------------------------------+---------------------------------+-------------------------------+----------------------------+---------------------------+-------------------------+-----------------------------+----------------------+------------------------+-------------------------------+--------------------------------+------------------------------+-------------------------------+--------------------------------+------------------------------+--------------------------+--------------------------------------+------------------------------+-------------------------------+---------------------------------------+---------------------------------+--------------------------------------------------+---------------------------------+---------------------------+----------------------------+----------------------------------+---------------------------------+---------------------------------+---------------------------------+---------------------------------+----------------------------------------+\n",
      "|             gmap_id|             address|avg_rating|            category|         description|               hours|          latitude|         longitude|          store_name|num_of_reviews|price|    relative_results|              state|  MISC_Accessibility|      MISC_Amenities|MISC_Atmosphere|       MISC_Crowd| MISC_Dining_options|MISC_Highlights|      MISC_Offerings|       MISC_Payments|       MISC_Planning|    MISC_Popular_for|MISC_Recycling|MISC_Service_options|  zip|      zip_city|zip_state|     zip_county|irs_estimated_population|permanent_closed|price_numeric|avg_predicted_sentiment|     sentiment_std|review_count|  shrunk_sentiment|MISC_Accessibility_Wheelchair_accessible_entrance_flag|MISC_Accessibility_Wheelchair_accessible_restroom_flag|MISC_Accessibility_Wheelchair_accessible_parking_lot_flag|MISC_Amenities_Good_for_kids_flag|MISC_Amenities_High_chairs_flag|MISC_Amenities_Restroom_flag|MISC_Atmosphere_Casual_flag|MISC_Atmosphere_Cozy_flag|MISC_Atmosphere_Romantic_flag|MISC_Crowd_Groups_flag|MISC_Crowd_Tourists_flag|MISC_Crowd_Family-friendly_flag|MISC_Dining_options_Dessert_flag|MISC_Dining_options_Lunch_flag|MISC_Dining_options_Dinner_flag|MISC_Offerings_Comfort_food_flag|MISC_Offerings_Quick_bite_flag|MISC_Offerings_Coffee_flag|MISC_Payments_NFC_mobile_payments_flag|MISC_Payments_Debit_cards_flag|MISC_Payments_Credit_cards_flag|MISC_Planning_Accepts_reservations_flag|MISC_Planning_LGBTQ_friendly_flag|MISC_Planning_Dinner_reservations_recommended_flag|MISC_Popular_for_Solo_dining_flag|MISC_Popular_for_Lunch_flag|MISC_Popular_for_Dinner_flag|MISC_Service_options_Delivery_flag|MISC_Service_options_Takeout_flag|MISC_Service_options_Dine-in_flag|MISC_Highlights_Fast_service_flag|MISC_Highlights_Great_coffee_flag|MISC_Highlights_Great_tea_selection_flag|\n",
      "+--------------------+--------------------+----------+--------------------+--------------------+--------------------+------------------+------------------+--------------------+--------------+-----+--------------------+-------------------+--------------------+--------------------+---------------+-----------------+--------------------+---------------+--------------------+--------------------+--------------------+--------------------+--------------+--------------------+-----+--------------+---------+---------------+------------------------+----------------+-------------+-----------------------+------------------+------------+------------------+------------------------------------------------------+------------------------------------------------------+---------------------------------------------------------+---------------------------------+-------------------------------+----------------------------+---------------------------+-------------------------+-----------------------------+----------------------+------------------------+-------------------------------+--------------------------------+------------------------------+-------------------------------+--------------------------------+------------------------------+--------------------------+--------------------------------------+------------------------------+-------------------------------+---------------------------------------+---------------------------------+--------------------------------------------------+---------------------------------+---------------------------+----------------------------+----------------------------------+---------------------------------+---------------------------------+---------------------------------+---------------------------------+----------------------------------------+\n",
      "|0x89e85a90fa80ea7...|Checkers, 550 Wil...|       3.5|[Fast food restau...|Chain eatery serv...|[[Monday, 11AM–1A...|        40.7996343|-72.86699759999999|            Checkers|           426|    $|[0x89e85a90fe4fe4...|Closed ⋅ Opens 11AM|[Wheelchair acces...|     [Good for kids]|       [Casual]|[Family-friendly]|[Breakfast, Lunch...| [Fast service]|[Kids' menu, Late...|[Debit cards, Cre...|                null|[Lunch, Dinner, S...|          null|[Outdoor seating,...|11967|       Shirley|       NY| Suffolk County|                 25560.0|               0|            1|     3.1702048057536985|1.0784551420278028|          11|3.6295623775899735|                                                     1|                                                     1|                                                        1|                                1|                              0|                           0|                          1|                        0|                            0|                     0|                       0|                              1|                               1|                             1|                              1|                               0|                             1|                         0|                                     0|                             1|                              1|                                      0|                                0|                                                 0|                                1|                          1|                           1|                                 1|                                1|                                1|                                1|                                0|                                       0|\n",
      "|0x89c2c219189e518...|Momo Asian Fusion...|       4.6|[Japanese restaur...|                null|[[Friday, 11AM–9:...|41.121023199999996|       -73.9436054|   Momo Asian Fusion|            88| null|[0x89c2ea07be85c3...|Closed ⋅ Opens 11AM|[Wheelchair acces...|[Good for kids, H...| [Casual, Cozy]|         [Groups]|           [Dessert]|           null|[Comfort food, He...|      [Credit cards]|[Accepts reservat...|[Lunch, Dinner, S...|          null|[Delivery, Takeou...|10989|Valley Cottage|       NY|Rockland County|                  8770.0|               0|            0|       4.58498825475099|0.5092351974776369|           5|  4.28489988932358|                                                     1|                                                     0|                                                        0|                                1|                              1|                           0|                          1|                        1|                            0|                     1|                       0|                              0|                               1|                             0|                              0|                               1|                             1|                         0|                                     0|                             0|                              1|                                      1|                                0|                                                 0|                                1|                          1|                           1|                                 1|                                1|                                1|                                0|                                0|                                       0|\n",
      "|0x8085b6a8ebae49f...|Rosso Pizzeria & ...|       4.2|[Pizza restaurant...|Neapolitan pizza,...|[[Saturday, 11:30...|           38.2328|      -122.6372028|Rosso Pizzeria & ...|            78| null|[0x8085b41d6183b8...| Permanently closed|                null|     [Good for kids]|           null|             null|                null|           null|                null|                null|                null|                null|          null|          [Delivery]|94952|      Petaluma|       CA|  Sonoma County|                 28770.0|               1|            0|      3.864661623144518|0.9601397247395762|           5| 4.044791012121423|                                                     0|                                                     0|                                                        0|                                1|                              0|                           0|                          0|                        0|                            0|                     0|                       0|                              0|                               0|                             0|                              0|                               0|                             0|                         0|                                     0|                             0|                              0|                                      0|                                0|                                                 0|                                0|                          0|                           0|                                 1|                                0|                                0|                                0|                                0|                                       0|\n",
      "+--------------------+--------------------+----------+--------------------+--------------------+--------------------+------------------+------------------+--------------------+--------------+-----+--------------------+-------------------+--------------------+--------------------+---------------+-----------------+--------------------+---------------+--------------------+--------------------+--------------------+--------------------+--------------+--------------------+-----+--------------+---------+---------------+------------------------+----------------+-------------+-----------------------+------------------+------------+------------------+------------------------------------------------------+------------------------------------------------------+---------------------------------------------------------+---------------------------------+-------------------------------+----------------------------+---------------------------+-------------------------+-----------------------------+----------------------+------------------------+-------------------------------+--------------------------------+------------------------------+-------------------------------+--------------------------------+------------------------------+--------------------------+--------------------------------------+------------------------------+-------------------------------+---------------------------------------+---------------------------------+--------------------------------------------------+---------------------------------+---------------------------+----------------------------+----------------------------------+---------------------------------+---------------------------------+---------------------------------+---------------------------------+----------------------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "business_df_clean.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6a996a-2798-43c1-bf6a-03bfa3f78cf3",
   "metadata": {},
   "source": [
    "#### Compare model performance on predicting closure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e3c323c-f7b3-4865-82a8-234521ce1cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Weights: 1.0 6.365726454865487\n",
      "Class counts: 146469 23009\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, when, isnan\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier, GBTClassifier\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 1. Feature Columns\n",
    "# -----------------------------------------------------\n",
    "feature_cols = [\n",
    "    \"avg_rating\", \n",
    "    \"price_numeric\", \n",
    "    \"num_of_reviews\", \n",
    "    \"irs_estimated_population\",\n",
    "    \"shrunk_sentiment\", \n",
    "    \"sentiment_std\",\n",
    "]\n",
    "\n",
    "one_hot_cols = [c for c in business_df_clean.columns if c.endswith(\"_flag\")] \n",
    "feature_cols += one_hot_cols\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 2. Check for missing columns (safety)\n",
    "# -----------------------------------------------------\n",
    "missing = [c for c in feature_cols if c not in business_df_clean.columns]\n",
    "if missing:\n",
    "    raise Exception(f\"Missing required feature columns: {missing}\")\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 3. Clean NaN / Null values\n",
    "# -----------------------------------------------------\n",
    "for c in feature_cols:\n",
    "    business_df_clean = business_df_clean.withColumn(\n",
    "        c, when(isnan(col(c)) | col(c).isNull(), 0).otherwise(col(c))\n",
    "    )\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 4. Compute class weights\n",
    "# -----------------------------------------------------\n",
    "counts = business_df_clean.groupBy(\"permanent_closed\").count().collect()\n",
    "count_0 = next(r['count'] for r in counts if r['permanent_closed'] == 0)\n",
    "count_1 = next(r['count'] for r in counts if r['permanent_closed'] == 1)\n",
    "\n",
    "majority = max(count_0, count_1)\n",
    "minority = min(count_0, count_1)\n",
    "\n",
    "weight_for_0 = majority / count_0\n",
    "weight_for_1 = majority / count_1\n",
    "\n",
    "business_df_clean = business_df_clean.withColumn(\n",
    "    \"classWeight\",\n",
    "    when(col(\"permanent_closed\") == 0, weight_for_0).otherwise(weight_for_1)\n",
    ")\n",
    "\n",
    "print(\"Class Weights:\", weight_for_0, weight_for_1)\n",
    "print(\"Class counts:\", count_0, count_1)\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 5. Train/test split\n",
    "# -----------------------------------------------------\n",
    "train_df, test_df = business_df_clean.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 6. Assemble features\n",
    "# -----------------------------------------------------\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=feature_cols,\n",
    "    outputCol=\"features\",\n",
    "    handleInvalid=\"keep\"   # <---- prevents schema errors\n",
    ")\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 7. Evaluators\n",
    "# -----------------------------------------------------\n",
    "evaluator_auc = BinaryClassificationEvaluator(\n",
    "    labelCol=\"permanent_closed\", metricName=\"areaUnderROC\")\n",
    "evaluator_acc = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"permanent_closed\", metricName=\"accuracy\")\n",
    "evaluator_f1 = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"permanent_closed\", metricName=\"f1\")\n",
    "evaluator_precision = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"permanent_closed\", metricName=\"weightedPrecision\")\n",
    "evaluator_recall = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"permanent_closed\", metricName=\"weightedRecall\")\n",
    "\n",
    "def evaluate_model(predictions, name=\"Model\"):\n",
    "    auc = evaluator_auc.evaluate(predictions)\n",
    "    acc = evaluator_acc.evaluate(predictions)\n",
    "    f1 = evaluator_f1.evaluate(predictions)\n",
    "    precision = evaluator_precision.evaluate(predictions)\n",
    "    recall = evaluator_recall.evaluate(predictions)\n",
    "\n",
    "    print(f\"\\n===== {name} Evaluation =====\")\n",
    "    print(f\"AUC:       {auc:.4f}\")\n",
    "    print(f\"Accuracy:  {acc:.4f}\")\n",
    "    print(f\"F1 Score:  {f1:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905d1a87-10c7-4ac4-9b4e-78c884fb8f35",
   "metadata": {},
   "source": [
    "#### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a35b76bb-d075-4b29-8320-4dab8d902fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: 117368, Class 1: 18444, Weight ratio: 6.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/12/01 18:19:01 WARN com.github.fommil.netlib.BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n",
      "25/12/01 18:19:01 WARN com.github.fommil.netlib.BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Logistic Regression (Weighted) Evaluation =====\n",
      "AUC:       0.9566\n",
      "Accuracy:  0.8944\n",
      "F1 Score:  0.9043\n",
      "Precision: 0.9309\n",
      "Recall:    0.8944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2202:==========================================>           (18 + 5) / 23]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Confusion Matrix =====\n",
      "          Predicted 0  Predicted 1\n",
      "Actual 0      25814.0       3261.0\n",
      "Actual 1        302.0       4356.0\n",
      "\n",
      "===== Logistic Regression Feature Importance =====\n",
      "                                                  feature   coefficient\n",
      "                              MISC_Atmosphere_Casual_flag -1.499952e+00\n",
      "                        MISC_Service_options_Takeout_flag -1.430408e+00\n",
      "                        MISC_Popular_for_Solo_dining_flag -1.269532e+00\n",
      "                        MISC_Amenities_Good_for_kids_flag  1.262651e+00\n",
      "                           MISC_Offerings_Quick_bite_flag -1.238925e+00\n",
      "                        MISC_Service_options_Dine-in_flag -1.224021e+00\n",
      "                           MISC_Payments_Debit_cards_flag  1.159287e+00\n",
      "       MISC_Planning_Dinner_reservations_recommended_flag -1.066499e+00\n",
      "                          MISC_Payments_Credit_cards_flag -1.044560e+00\n",
      "                       MISC_Service_options_Delivery_flag  1.034298e+00\n",
      "                   MISC_Payments_NFC_mobile_payments_flag -9.798427e-01\n",
      "   MISC_Accessibility_Wheelchair_accessible_entrance_flag -9.391593e-01\n",
      "                                 MISC_Crowd_Tourists_flag -7.590843e-01\n",
      "                                         shrunk_sentiment  6.991758e-01\n",
      "                          MISC_Dining_options_Dinner_flag  5.579440e-01\n",
      "                          MISC_Crowd_Family-friendly_flag -5.356920e-01\n",
      "                               MISC_Offerings_Coffee_flag  4.127446e-01\n",
      "                  MISC_Planning_Accepts_reservations_flag  3.954233e-01\n",
      "   MISC_Accessibility_Wheelchair_accessible_restroom_flag -3.923539e-01\n",
      "                           MISC_Dining_options_Lunch_flag  3.315651e-01\n",
      "                             MISC_Popular_for_Dinner_flag -2.895614e-01\n",
      "                                MISC_Atmosphere_Cozy_flag -2.845733e-01\n",
      "                             MISC_Amenities_Restroom_flag  2.322488e-01\n",
      "                            MISC_Atmosphere_Romantic_flag  2.120433e-01\n",
      "                                               avg_rating -2.084407e-01\n",
      "                         MISC_Offerings_Comfort_food_flag  1.973946e-01\n",
      "                 MISC_Highlights_Great_tea_selection_flag  1.730030e-01\n",
      "                                            price_numeric  1.260936e-01\n",
      "                        MISC_Highlights_Great_coffee_flag -1.141882e-01\n",
      "                        MISC_Highlights_Fast_service_flag -1.101791e-01\n",
      "                        MISC_Planning_LGBTQ_friendly_flag  1.012538e-01\n",
      "                          MISC_Amenities_High_chairs_flag  9.727400e-02\n",
      "MISC_Accessibility_Wheelchair_accessible_parking_lot_flag -8.285027e-02\n",
      "                              MISC_Popular_for_Lunch_flag  3.957890e-02\n",
      "                         MISC_Dining_options_Dessert_flag  3.144293e-02\n",
      "                                            sentiment_std -2.365067e-02\n",
      "                                   MISC_Crowd_Groups_flag -1.436679e-02\n",
      "                                           num_of_reviews -2.894697e-03\n",
      "                                 irs_estimated_population  5.596202e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, when\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "import pandas as pd\n",
    "\n",
    "# ============================================================\n",
    "# 0. Handle class imbalance (recommended: class weights)\n",
    "# ============================================================\n",
    "\n",
    "# Count classes\n",
    "counts = train_df.groupBy(\"permanent_closed\").count().collect()\n",
    "count_0 = [r[\"count\"] for r in counts if r[\"permanent_closed\"] == 0][0]\n",
    "count_1 = [r[\"count\"] for r in counts if r[\"permanent_closed\"] == 1][0]\n",
    "\n",
    "# Assign weights: majority = 1, minority = ratio\n",
    "ratio = count_0 / count_1\n",
    "train_df_balanced = train_df.withColumn(\n",
    "    \"weight\",\n",
    "    when(col(\"permanent_closed\") == 1, ratio).otherwise(1.0)\n",
    ")\n",
    "\n",
    "print(f\"Class 0: {count_0}, Class 1: {count_1}, Weight ratio: {ratio:.2f}\")\n",
    "\n",
    "# ============================================================\n",
    "# 1. Logistic Regression with CV\n",
    "# ============================================================\n",
    "\n",
    "lr = LogisticRegression(\n",
    "    labelCol=\"permanent_closed\",\n",
    "    featuresCol=\"features\",\n",
    "    weightCol=\"weight\",   # ⬅ KEY FIX FOR IMBALANCE\n",
    "    maxIter=25\n",
    ")\n",
    "\n",
    "lr_pipeline = Pipeline(stages=[assembler, lr])\n",
    "\n",
    "paramGrid_lr = (ParamGridBuilder()\n",
    "    .addGrid(lr.regParam, [0.0, 0.01, 0.1])\n",
    "    .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0])\n",
    "    .build()\n",
    ")\n",
    "\n",
    "cv_lr = CrossValidator(\n",
    "    estimator=lr_pipeline,\n",
    "    estimatorParamMaps=paramGrid_lr,\n",
    "    evaluator=evaluator_auc,\n",
    "    numFolds=3,\n",
    "    parallelism=2\n",
    ")\n",
    "\n",
    "cv_model_lr = cv_lr.fit(train_df_balanced)\n",
    "predictions_lr = cv_model_lr.transform(test_df)\n",
    "\n",
    "evaluate_model(predictions_lr, \"Logistic Regression (Weighted)\")\n",
    "\n",
    "# ============================================================\n",
    "# 2. Confusion Matrix\n",
    "# ============================================================\n",
    "\n",
    "predictionAndLabels = predictions_lr.select(\"prediction\", \"permanent_closed\") \\\n",
    "                                   .rdd.map(lambda r: (float(r[\"prediction\"]), float(r[\"permanent_closed\"])))\n",
    "\n",
    "metrics = MulticlassMetrics(predictionAndLabels)\n",
    "conf_matrix = metrics.confusionMatrix().toArray()\n",
    "\n",
    "conf_df = pd.DataFrame(\n",
    "    conf_matrix,\n",
    "    index=[\"Actual 0\", \"Actual 1\"],\n",
    "    columns=[\"Predicted 0\", \"Predicted 1\"]\n",
    ")\n",
    "\n",
    "print(\"\\n===== Confusion Matrix =====\")\n",
    "print(conf_df)\n",
    "\n",
    "# ============================================================\n",
    "# 3. Feature Importance (LR coefficients)\n",
    "# ============================================================\n",
    "\n",
    "lr_model = cv_model_lr.bestModel.stages[-1]\n",
    "\n",
    "feature_importance = pd.DataFrame({\n",
    "    \"feature\": feature_cols,\n",
    "    \"coefficient\": lr_model.coefficients\n",
    "})\n",
    "\n",
    "feature_importance[\"abs_coeff\"] = feature_importance[\"coefficient\"].abs()\n",
    "feature_importance = feature_importance.sort_values(\"abs_coeff\", ascending=False)\n",
    "\n",
    "print(\"\\n===== Logistic Regression Feature Importance =====\")\n",
    "print(feature_importance[[\"feature\", \"coefficient\"]].to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76dc5180-5309-4e44-a432-ee053de08fe9",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "653284ff-f572-415f-ab15-aefaa0a23719",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import logging\n",
    "\n",
    "# If you haven't already, create Spark session\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# Set Spark log level to WARN or ERROR (suppress INFO and repeated WARN)\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "# Optionally, suppress some specific loggers\n",
    "log4jLogger = spark._jvm.org.apache.log4j\n",
    "log4jLogger.LogManager.getLogger(\"org.apache.spark.scheduler.DAGScheduler\").setLevel(log4jLogger.Level.ERROR)\n",
    "log4jLogger.LogManager.getLogger(\"org.apache.spark.storage.BlockManager\").setLevel(log4jLogger.Level.ERROR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90e7b64e-b11c-4c4b-b5e8-f6a6f85f0937",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Random Forest (Weighted) Evaluation =====\n",
      "AUC:       0.9694\n",
      "Accuracy:  0.9107\n",
      "F1 Score:  0.9185\n",
      "Precision: 0.9411\n",
      "Recall:    0.9107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2647:==>                                                   (1 + 22) / 23]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Random Forest Confusion Matrix =====\n",
      "          Predicted 0  Predicted 1\n",
      "Actual 0      26226.0       2849.0\n",
      "Actual 1        164.0       4494.0\n",
      "\n",
      "===== Random Forest Feature Importance =====\n",
      "                                                  feature  importance\n",
      "                        MISC_Popular_for_Solo_dining_flag    0.165834\n",
      "                              MISC_Atmosphere_Casual_flag    0.157704\n",
      "                           MISC_Offerings_Quick_bite_flag    0.127008\n",
      "                        MISC_Service_options_Takeout_flag    0.099606\n",
      "                             MISC_Popular_for_Dinner_flag    0.057428\n",
      "                                           num_of_reviews    0.055458\n",
      "                              MISC_Popular_for_Lunch_flag    0.054846\n",
      "                        MISC_Service_options_Dine-in_flag    0.049832\n",
      "                                   MISC_Crowd_Groups_flag    0.037430\n",
      "   MISC_Accessibility_Wheelchair_accessible_entrance_flag    0.033213\n",
      "                                 MISC_Crowd_Tourists_flag    0.020021\n",
      "                        MISC_Amenities_Good_for_kids_flag    0.018924\n",
      "                                MISC_Atmosphere_Cozy_flag    0.012404\n",
      "                   MISC_Payments_NFC_mobile_payments_flag    0.011979\n",
      "                         MISC_Offerings_Comfort_food_flag    0.011451\n",
      "                         MISC_Dining_options_Dessert_flag    0.008718\n",
      "                           MISC_Dining_options_Lunch_flag    0.008696\n",
      "                          MISC_Dining_options_Dinner_flag    0.008517\n",
      "                           MISC_Payments_Debit_cards_flag    0.006161\n",
      "                        MISC_Highlights_Fast_service_flag    0.005637\n",
      "                       MISC_Service_options_Delivery_flag    0.005582\n",
      "                          MISC_Payments_Credit_cards_flag    0.005544\n",
      "                                            price_numeric    0.004859\n",
      "                          MISC_Amenities_High_chairs_flag    0.004711\n",
      "                                               avg_rating    0.004505\n",
      "                          MISC_Crowd_Family-friendly_flag    0.003636\n",
      "                                         shrunk_sentiment    0.002565\n",
      "                  MISC_Planning_Accepts_reservations_flag    0.002392\n",
      "                                 irs_estimated_population    0.002194\n",
      "                        MISC_Highlights_Great_coffee_flag    0.001993\n",
      "                             MISC_Amenities_Restroom_flag    0.001878\n",
      "                                            sentiment_std    0.001846\n",
      "                               MISC_Offerings_Coffee_flag    0.001765\n",
      "       MISC_Planning_Dinner_reservations_recommended_flag    0.001741\n",
      "   MISC_Accessibility_Wheelchair_accessible_restroom_flag    0.001246\n",
      "MISC_Accessibility_Wheelchair_accessible_parking_lot_flag    0.001133\n",
      "                            MISC_Atmosphere_Romantic_flag    0.000616\n",
      "                 MISC_Highlights_Great_tea_selection_flag    0.000601\n",
      "                        MISC_Planning_LGBTQ_friendly_flag    0.000325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "import pandas as pd\n",
    "\n",
    "# -------------------------\n",
    "# Random Forest + Pipeline\n",
    "# -------------------------\n",
    "rf = RandomForestClassifier(\n",
    "    labelCol=\"permanent_closed\",\n",
    "    featuresCol=\"features\",\n",
    "    weightCol=\"weight\"\n",
    ")\n",
    "\n",
    "rf_pipeline = Pipeline(stages=[assembler, rf])\n",
    "\n",
    "paramGrid_rf = (ParamGridBuilder()\n",
    "                .addGrid(rf.maxDepth, [5, 10])\n",
    "                .addGrid(rf.numTrees, [50, 100])\n",
    "                .build())\n",
    "\n",
    "cv_rf = CrossValidator(\n",
    "    estimator=rf_pipeline,\n",
    "    estimatorParamMaps=paramGrid_rf,\n",
    "    evaluator=evaluator_auc,\n",
    "    numFolds=3,\n",
    "    parallelism=2\n",
    ")\n",
    "\n",
    "cv_model_rf = cv_rf.fit(train_df_balanced)\n",
    "predictions_rf = cv_model_rf.transform(test_df)\n",
    "\n",
    "evaluate_model(predictions_rf, \"Random Forest (Weighted)\")\n",
    "\n",
    "predictionAndLabels = predictions_rf.select(\"prediction\", \"permanent_closed\") \\\n",
    "                                   .rdd.map(lambda row: (float(row['prediction']), float(row['permanent_closed'])))\n",
    "\n",
    "metrics = MulticlassMetrics(predictionAndLabels)\n",
    "conf_matrix = metrics.confusionMatrix().toArray()\n",
    "\n",
    "print(\"\\n===== Random Forest Confusion Matrix =====\")\n",
    "conf_df = pd.DataFrame(conf_matrix, \n",
    "                       index=[\"Actual 0\", \"Actual 1\"], \n",
    "                       columns=[\"Predicted 0\", \"Predicted 1\"])\n",
    "print(conf_df)\n",
    "\n",
    "rf_model = cv_model_rf.bestModel.stages[-1]\n",
    "\n",
    "feature_importance = pd.DataFrame({\n",
    "    \"feature\": feature_cols,\n",
    "    \"importance\": rf_model.featureImportances.toArray()\n",
    "}).sort_values(\"importance\", ascending=False)\n",
    "\n",
    "print(\"\\n===== Random Forest Feature Importance =====\")\n",
    "print(feature_importance.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a58ee1b-8a7b-46a5-ae4b-c422808fdf34",
   "metadata": {},
   "source": [
    "#### Gradient-Boosted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a4ae3c9-6518-429a-8f28-70e725e03113",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Gradient-Boosted Trees Evaluation =====\n",
      "AUC:       0.9699\n",
      "Accuracy:  0.9164\n",
      "F1 Score:  0.9233\n",
      "Precision: 0.9428\n",
      "Recall:    0.9164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6716:============================================>         (19 + 4) / 23]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Gradient-Boosted Trees Confusion Matrix =====\n",
      "          Predicted 0  Predicted 1\n",
      "Actual 0      26442.0       2633.0\n",
      "Actual 1        187.0       4471.0\n",
      "\n",
      "===== Gradient-Boosted Trees Feature Importance =====\n",
      "                                                  feature  importance\n",
      "                        MISC_Popular_for_Solo_dining_flag    0.444756\n",
      "                        MISC_Service_options_Takeout_flag    0.118190\n",
      "                                           num_of_reviews    0.084436\n",
      "                              MISC_Atmosphere_Casual_flag    0.064586\n",
      "                        MISC_Amenities_Good_for_kids_flag    0.039162\n",
      "                        MISC_Service_options_Dine-in_flag    0.037595\n",
      "   MISC_Accessibility_Wheelchair_accessible_entrance_flag    0.025374\n",
      "                         MISC_Offerings_Comfort_food_flag    0.021081\n",
      "                   MISC_Payments_NFC_mobile_payments_flag    0.020428\n",
      "                                            price_numeric    0.015760\n",
      "                       MISC_Service_options_Delivery_flag    0.013168\n",
      "                           MISC_Offerings_Quick_bite_flag    0.013030\n",
      "                           MISC_Payments_Debit_cards_flag    0.011907\n",
      "                  MISC_Planning_Accepts_reservations_flag    0.011122\n",
      "                                               avg_rating    0.010353\n",
      "                          MISC_Dining_options_Dinner_flag    0.008851\n",
      "                                   MISC_Crowd_Groups_flag    0.007290\n",
      "                                 irs_estimated_population    0.005763\n",
      "                           MISC_Dining_options_Lunch_flag    0.005381\n",
      "                         MISC_Dining_options_Dessert_flag    0.004595\n",
      "                             MISC_Popular_for_Dinner_flag    0.004038\n",
      "   MISC_Accessibility_Wheelchair_accessible_restroom_flag    0.003995\n",
      "                                         shrunk_sentiment    0.003887\n",
      "                             MISC_Amenities_Restroom_flag    0.003787\n",
      "                          MISC_Payments_Credit_cards_flag    0.003496\n",
      "                            MISC_Atmosphere_Romantic_flag    0.003167\n",
      "                          MISC_Crowd_Family-friendly_flag    0.002898\n",
      "                               MISC_Offerings_Coffee_flag    0.002583\n",
      "                                MISC_Atmosphere_Cozy_flag    0.002067\n",
      "                              MISC_Popular_for_Lunch_flag    0.001850\n",
      "                                            sentiment_std    0.001019\n",
      "                          MISC_Amenities_High_chairs_flag    0.000995\n",
      "       MISC_Planning_Dinner_reservations_recommended_flag    0.000910\n",
      "MISC_Accessibility_Wheelchair_accessible_parking_lot_flag    0.000821\n",
      "                 MISC_Highlights_Great_tea_selection_flag    0.000491\n",
      "                        MISC_Highlights_Fast_service_flag    0.000409\n",
      "                                 MISC_Crowd_Tourists_flag    0.000403\n",
      "                        MISC_Highlights_Great_coffee_flag    0.000253\n",
      "                        MISC_Planning_LGBTQ_friendly_flag    0.000104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 0. Handle class imbalance (recommended for GBT)\n",
    "# ---------------------------------------------------------\n",
    "# Compute class weights (inverse frequency)\n",
    "counts = train_df.groupBy(\"permanent_closed\").count().toPandas()\n",
    "n0 = counts[counts[\"permanent_closed\"] == 0][\"count\"].values[0]\n",
    "n1 = counts[counts[\"permanent_closed\"] == 1][\"count\"].values[0]\n",
    "\n",
    "minority_weight = max(n0, n1) / min(n0, n1)\n",
    "\n",
    "# Attach weight column\n",
    "train_df = train_df.withColumn(\n",
    "    \"weight\",\n",
    "    (1.0 * (train_df.permanent_closed == 1).cast(\"int\")) * minority_weight +\n",
    "    (1.0 * (train_df.permanent_closed == 0).cast(\"int\"))\n",
    ")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1. Gradient-Boosted Trees CV\n",
    "# ---------------------------------------------------------\n",
    "gbt = GBTClassifier(\n",
    "    labelCol=\"permanent_closed\",\n",
    "    featuresCol=\"features\",\n",
    "    weightCol=\"weight\",\n",
    "    maxIter=50,   # upper bound, CV will tune\n",
    "    maxDepth=5    # upper bound, CV will tune\n",
    ")\n",
    "\n",
    "gbt_pipeline = Pipeline(stages=[assembler, gbt])\n",
    "\n",
    "paramGrid_gbt = (ParamGridBuilder()\n",
    "                 .addGrid(gbt.maxDepth, [3, 5])\n",
    "                 .addGrid(gbt.maxIter, [20, 50])\n",
    "                 .build())\n",
    "\n",
    "cv_gbt = CrossValidator(\n",
    "    estimator=gbt_pipeline,\n",
    "    estimatorParamMaps=paramGrid_gbt,\n",
    "    evaluator=evaluator_auc,\n",
    "    numFolds=3,\n",
    "    parallelism=2\n",
    ")\n",
    "\n",
    "cv_model_gbt = cv_gbt.fit(train_df)\n",
    "predictions_gbt = cv_model_gbt.transform(test_df)\n",
    "\n",
    "evaluate_model(predictions_gbt, \"Gradient-Boosted Trees\")\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2. Confusion Matrix\n",
    "# ---------------------------------------------------------\n",
    "predictionAndLabels = predictions_gbt.select(\"prediction\", \"permanent_closed\") \\\n",
    "    .rdd.map(lambda row: (float(row[\"prediction\"]), float(row[\"permanent_closed\"])))\n",
    "\n",
    "metrics = MulticlassMetrics(predictionAndLabels)\n",
    "conf_matrix = metrics.confusionMatrix().toArray()\n",
    "\n",
    "print(\"\\n===== Gradient-Boosted Trees Confusion Matrix =====\")\n",
    "conf_df = pd.DataFrame(\n",
    "    conf_matrix,\n",
    "    index=[\"Actual 0\", \"Actual 1\"],\n",
    "    columns=[\"Predicted 0\", \"Predicted 1\"]\n",
    ")\n",
    "print(conf_df)\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3. Feature Importance\n",
    "# ---------------------------------------------------------\n",
    "gbt_model = cv_model_gbt.bestModel.stages[-1]\n",
    "\n",
    "feature_importance = pd.DataFrame({\n",
    "    \"feature\": feature_cols,\n",
    "    \"importance\": gbt_model.featureImportances.toArray()\n",
    "}).sort_values(\"importance\", ascending=False)\n",
    "\n",
    "print(\"\\n===== Gradient-Boosted Trees Feature Importance =====\")\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "print(feature_importance.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93f2aa8-c8c1-4ff2-8fc5-a1c710da2465",
   "metadata": {},
   "source": [
    "#### Interpret feature importance and direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52629d39-b984-4007-b030-13624bdc3807",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#############################################################\n",
      "###  Top Predictors with GBT Importance and Direction ###\n",
      "#############################################################\n",
      "\n",
      "                                  Feature_Clean  GBT_Importance  LR_Coefficient Closure_Effect_Direction\n",
      "                        Popular for Solo dining        0.444756       -0.468713 ↓ Strong Survival Driver\n",
      "                        Service options Takeout        0.118190       -0.313002 ↓ Strong Survival Driver\n",
      "                                 num of reviews        0.084436       -0.559200 ↓ Strong Survival Driver\n",
      "                              Atmosphere Casual        0.064586       -0.443714 ↓ Strong Survival Driver\n",
      "                        Amenities Good for kids        0.039162        0.405848  ↑ Strong Failure Driver\n",
      "                        Service options Dine-in        0.037595       -0.500027 ↓ Strong Survival Driver\n",
      "   Accessibility Wheelchair accessible entrance        0.025374       -0.314937 ↓ Strong Survival Driver\n",
      "                         Offerings Comfort food        0.021081        0.018591    ↑ Weak Failure Driver\n",
      "                   Payments NFC mobile payments        0.020428       -0.317325 ↓ Strong Survival Driver\n",
      "                                  price numeric        0.015760        0.021443    ↑ Weak Failure Driver\n",
      "                       Service options Delivery        0.013168        0.277825  ↑ Strong Failure Driver\n",
      "                           Offerings Quick bite        0.013030       -0.461127 ↓ Strong Survival Driver\n",
      "                           Payments Debit cards        0.011907        0.166381  ↑ Strong Failure Driver\n",
      "                  Planning Accepts reservations        0.011122        0.127446    ↑ Weak Failure Driver\n",
      "                                     avg rating        0.010353       -0.020302   ↓ Weak Survival Driver\n",
      "                          Dining options Dinner        0.008851        0.184513  ↑ Strong Failure Driver\n",
      "                                   Crowd Groups        0.007290       -0.041978   ↓ Weak Survival Driver\n",
      "                       irs estimated population        0.005763        0.003621   Neutral / Not Selected\n",
      "                           Dining options Lunch        0.005381        0.138207    ↑ Weak Failure Driver\n",
      "                         Dining options Dessert        0.004595        0.000000   Neutral / Not Selected\n",
      "                             Popular for Dinner        0.004038       -0.107882   ↓ Weak Survival Driver\n",
      "   Accessibility Wheelchair accessible restroom        0.003995       -0.103929   ↓ Weak Survival Driver\n",
      "                               shrunk sentiment        0.003887        0.021152    ↑ Weak Failure Driver\n",
      "                             Amenities Restroom        0.003787        0.007117   Neutral / Not Selected\n",
      "                          Payments Credit cards        0.003496       -0.181879 ↓ Strong Survival Driver\n",
      "                            Atmosphere Romantic        0.003167        0.000000   Neutral / Not Selected\n",
      "                          Crowd Family-friendly        0.002898       -0.029795   ↓ Weak Survival Driver\n",
      "                               Offerings Coffee        0.002583        0.036152    ↑ Weak Failure Driver\n",
      "                                Atmosphere Cozy        0.002067       -0.101754   ↓ Weak Survival Driver\n",
      "                              Popular for Lunch        0.001850       -0.020838   ↓ Weak Survival Driver\n",
      "                                  sentiment std        0.001019        0.000000   Neutral / Not Selected\n",
      "                          Amenities High chairs        0.000995        0.000000   Neutral / Not Selected\n",
      "       Planning Dinner reservations recommended        0.000910       -0.039116   ↓ Weak Survival Driver\n",
      "Accessibility Wheelchair accessible parking lot        0.000821       -0.033972   ↓ Weak Survival Driver\n",
      "                 Highlights Great tea selection        0.000491        0.000000   Neutral / Not Selected\n",
      "                        Highlights Fast service        0.000409       -0.037965   ↓ Weak Survival Driver\n",
      "                                 Crowd Tourists        0.000403       -0.235404 ↓ Strong Survival Driver\n",
      "                        Highlights Great coffee        0.000253        0.000000   Neutral / Not Selected\n",
      "                        Planning LGBTQ friendly        0.000104       -0.019140   ↓ Weak Survival Driver\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "# ============================================================\n",
    "# 0. Prepare features for Elastic Net Logistic Regression\n",
    "# ============================================================\n",
    "\n",
    "assembler_lasso = VectorAssembler(\n",
    "    inputCols=feature_cols,\n",
    "    outputCol=\"features_lasso\"\n",
    ")\n",
    "\n",
    "# Remove old features_lasso column if it exists\n",
    "if \"features_lasso\" in train_df.columns:\n",
    "    train_df = train_df.drop(\"features_lasso\")\n",
    "if \"features_lasso\" in test_df.columns:\n",
    "    test_df = test_df.drop(\"features_lasso\")\n",
    "\n",
    "train_df_lasso = assembler_lasso.transform(train_df)\n",
    "test_df_lasso = assembler_lasso.transform(test_df)\n",
    "\n",
    "# Standardize numeric features\n",
    "scaler = StandardScaler(inputCol=\"features_lasso\", outputCol=\"features_scaled\", withMean=True, withStd=True)\n",
    "scaler_model = scaler.fit(train_df_lasso)\n",
    "train_df_scaled = scaler_model.transform(train_df_lasso)\n",
    "test_df_scaled = scaler_model.transform(test_df_lasso)\n",
    "\n",
    "# ============================================================\n",
    "# 1. Train Elastic Net Logistic Regression (for direction)\n",
    "# ============================================================\n",
    "\n",
    "elastic_lr = LogisticRegression(\n",
    "    featuresCol=\"features_scaled\",\n",
    "    labelCol=\"permanent_closed\",\n",
    "    elasticNetParam=0.2,   # Elastic Net (mix of Lasso & Ridge)\n",
    "    regParam=0.01,\n",
    "    maxIter=50\n",
    ")\n",
    "\n",
    "elastic_model = elastic_lr.fit(train_df_scaled)\n",
    "\n",
    "# ============================================================\n",
    "# 2. Extract coefficients with direction\n",
    "# ============================================================\n",
    "\n",
    "elastic_coef = pd.DataFrame({\n",
    "    \"feature\": feature_cols,\n",
    "    \"LR_Coefficient\": elastic_model.coefficients.toArray()\n",
    "})\n",
    "elastic_coef[\"abs_coef\"] = elastic_coef[\"LR_Coefficient\"].abs()\n",
    "\n",
    "# ============================================================\n",
    "# 3. Gradient-Boosted Trees feature importance\n",
    "# ============================================================\n",
    "\n",
    "gbt_importances = gbt_model.featureImportances.toArray()\n",
    "if len(gbt_importances) != len(feature_cols):\n",
    "    usable_cols = feature_cols[:len(gbt_importances)]\n",
    "else:\n",
    "    usable_cols = feature_cols\n",
    "\n",
    "feature_importance_gbt = pd.DataFrame({\n",
    "    \"feature\": usable_cols,\n",
    "    \"GBT_Importance\": gbt_importances\n",
    "}).sort_values(\"GBT_Importance\", ascending=False)\n",
    "\n",
    "# ============================================================\n",
    "# 4. Merge GBT importance with LR coefficients\n",
    "# ============================================================\n",
    "\n",
    "final_df = feature_importance_gbt.merge(\n",
    "    elastic_coef,\n",
    "    on=\"feature\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# 5. Determine effect direction\n",
    "# ============================================================\n",
    "\n",
    "def determine_effect(coef):\n",
    "    if pd.isna(coef) or abs(coef) < 0.01:\n",
    "        return \"Neutral / Not Selected\"\n",
    "    elif coef > 0.15:\n",
    "        return \"↑ Strong Failure Driver\"\n",
    "    elif coef > 0:\n",
    "        return \"↑ Weak Failure Driver\"\n",
    "    elif coef < -0.15:\n",
    "        return \"↓ Strong Survival Driver\"\n",
    "    else:\n",
    "        return \"↓ Weak Survival Driver\"\n",
    "\n",
    "final_df[\"Closure_Effect_Direction\"] = final_df[\"LR_Coefficient\"].apply(determine_effect)\n",
    "\n",
    "# ============================================================\n",
    "# 6. Select top N features by GBT importance\n",
    "# ============================================================\n",
    "\n",
    "top_n = 50\n",
    "top_features = final_df.head(top_n).copy()\n",
    "\n",
    "# ============================================================\n",
    "# 7. Clean feature names for presentation\n",
    "# ============================================================\n",
    "\n",
    "top_features[\"Feature_Clean\"] = (\n",
    "    top_features[\"feature\"]\n",
    "    .str.replace(\"MISC_\", \"\", regex=False)\n",
    "    .str.replace(\"_flag\", \"\", regex=False)\n",
    "    .str.replace(\"_\", \" \", regex=False)\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# 8. Final presentation table\n",
    "# ============================================================\n",
    "\n",
    "final_cols = [\n",
    "    \"Feature_Clean\",\n",
    "    \"GBT_Importance\",\n",
    "    \"LR_Coefficient\",\n",
    "    \"Closure_Effect_Direction\"\n",
    "]\n",
    "\n",
    "print(\"\\n#############################################################\")\n",
    "print(\"###  Top Predictors with GBT Importance and Direction ###\")\n",
    "print(\"#############################################################\\n\")\n",
    "\n",
    "print(top_features[final_cols].to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a637f40-c041-4ba1-9b04-695294b46c1a",
   "metadata": {},
   "source": [
    "#### predict all dataset and store the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "52be3940-ffb5-4d00-a7e2-285d5dfb6789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------+-------------------------------+----------+--------------------+\n",
      "|gmap_id                              |store_name                     |prediction|closure_prob        |\n",
      "+-------------------------------------+-------------------------------+----------+--------------------+\n",
      "|0x89e85a90fa80ea79:0x2f56cdd1f58118f |Checkers                       |0.0       |0.007217116418191323|\n",
      "|0x89c2c219189e5189:0x684a238fa71eb176|Momo Asian Fusion              |0.0       |0.017988535282472868|\n",
      "|0x8085b6a8ebae49f1:0x9f24861c2d643f9a|Rosso Pizzeria & Mozzarella Bar|1.0       |0.9591585341045397  |\n",
      "|0x89c258545813c6bf:0x8ee1343834123591|Junior's Restaurant & Bakery   |1.0       |0.5504999064554688  |\n",
      "|0x880fc80bb9076013:0xf73fd28c4d61b7ae|Woori Village                  |0.0       |0.18938758140253537 |\n",
      "|0x80dce7e4827a029f:0xcb9497eb98076b9d|The Flame Broiler              |0.0       |0.05205610831563328 |\n",
      "|0x89c25baa8b6fb9c9:0x5c4f2f36d6850943|200 Fifth                      |1.0       |0.7581311727980395  |\n",
      "|0x89d0b747c5aaf579:0xd3ea18ab8ff58c3c|Wolffy's Grill and Marina      |0.0       |0.012345089241641037|\n",
      "|0x80dcd89c71f46e37:0x419d4c74a1fbfd1a|San Salvador Restaurant        |0.0       |0.004609386299243671|\n",
      "|0x89c292f56593548d:0x46bb4c98b1e2e015|La Herradura Inc II            |1.0       |0.5751841549502201  |\n",
      "+-------------------------------------+-------------------------------+----------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.functions import vector_to_array\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# 1️⃣ Transform all data\n",
    "all_predictions = cv_model_rf.bestModel.transform(business_df_clean)\n",
    "\n",
    "# 2️⃣ Convert SparseVector probability to array\n",
    "all_predictions = all_predictions.withColumn(\n",
    "    \"prob_array\",\n",
    "    vector_to_array(col(\"business_closure_prob\"))\n",
    ")\n",
    "\n",
    "# 3️⃣ Extract the probability of closure (class 1)\n",
    "all_predictions = all_predictions.withColumn(\n",
    "    \"closure_prob\",\n",
    "    col(\"prob_array\")[1]  # now safe\n",
    ")\n",
    "\n",
    "# 4️⃣ Select the final columns\n",
    "biz_closure_prob_df = all_predictions.select(\n",
    "    \"gmap_id\",\n",
    "    \"store_name\",\n",
    "    \"prediction\",\n",
    "    \"closure_prob\"\n",
    ")\n",
    "\n",
    "# 5️⃣ Show results\n",
    "biz_closure_prob_df.show(10, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f1638d85-40cd-4d9f-8c3a-5e824bb1bece",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "biz_closure_prob_df.write.mode(\"overwrite\").parquet(\"gs://msca-bdp-student-gcs/Group_5_final_project/biz_closure_prob_df/\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f7b951-b88e-4167-8fda-0292a18c774d",
   "metadata": {},
   "source": [
    "#### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bcf17966-2120-424f-9853-a98ca9252105",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|        avg_rating|\n",
      "+-------+------------------+\n",
      "|  count|            169478|\n",
      "|   mean| 4.199176294268276|\n",
      "| stddev|0.4117197819420847|\n",
      "|    min|               1.0|\n",
      "|    max|               5.0|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6838:=======>                                                (1 + 7) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|rating_bin|count|\n",
      "+----------+-----+\n",
      "|     1.5-2|   42|\n",
      "|     2-2.5|  486|\n",
      "|     2.5-3| 2874|\n",
      "|     3-3.5|12928|\n",
      "|     3.5-4|40745|\n",
      "|     4-4.5|75402|\n",
      "|     4.5-5|37001|\n",
      "+----------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, count, round\n",
    "\n",
    "# Basic statistics\n",
    "business_df.select(\"avg_rating\").describe().show()\n",
    "\n",
    "\n",
    "# Optional: Bin ratings into ranges (e.g., 1-2, 2-3, 3-4, 4-5)\n",
    "from pyspark.sql.functions import when\n",
    "\n",
    "from pyspark.sql.functions import when, col\n",
    "\n",
    "business_df = business_df.withColumn(\n",
    "    \"rating_bin\",\n",
    "    when(col(\"avg_predicted_sentiment\") < 1.5, \"1-1.5\") \\\n",
    "    .when(col(\"avg_predicted_sentiment\") < 2, \"1.5-2\") \\\n",
    "    .when(col(\"avg_predicted_sentiment\") < 2.5, \"2-2.5\") \\\n",
    "    .when(col(\"avg_predicted_sentiment\") < 3, \"2.5-3\") \\\n",
    "    .when(col(\"avg_predicted_sentiment\") < 3.5, \"3-3.5\") \\\n",
    "    .when(col(\"avg_predicted_sentiment\") < 4, \"3.5-4\") \\\n",
    "    .when(col(\"avg_predicted_sentiment\") < 4.5, \"4-4.5\") \\\n",
    "    .otherwise(\"4.5-5\")\n",
    ")\n",
    "\n",
    "\n",
    "business_df.groupBy(\"rating_bin\").agg(count(\"*\").alias(\"count\")) \\\n",
    "               .orderBy(\"rating_bin\") \\\n",
    "               .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a3826d6-1793-4324-8eb4-4beda6eb84d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------+------+----+--------------------+-------------+--------------------+--------------------+----------+--------------------+-----------+--------------------+------------------+------------------+--------------------+--------------+-----+--------------------+------------------+------------------+---------------+---------------+---------------+--------------------+-------------------+----------------------+-----------------+----------------------+---------------+--------------------+--------------------+-------------+-------------+--------------------+--------------+--------------------+-----+--------+---------+-------------+------------------------+\n",
      "|             gmap_id|     cust_name|rating|resp|                text|         time|             user_id|             address|avg_rating|            category|description|               hours|          latitude|         longitude|          store_name|num_of_reviews|price|    relative_results|             state|MISC_Accessibility|MISC_Activities| MISC_Amenities|MISC_Atmosphere|          MISC_Crowd|MISC_Dining_options|MISC_From_the_business|MISC_Getting_here|MISC_Health_and_safety|MISC_Highlights|MISC_Lodging_options|      MISC_Offerings|MISC_Payments|MISC_Planning|    MISC_Popular_for|MISC_Recycling|MISC_Service_options|  zip|zip_city|zip_state|   zip_county|irs_estimated_population|\n",
      "+--------------------+--------------+------+----+--------------------+-------------+--------------------+--------------------+----------+--------------------+-----------+--------------------+------------------+------------------+--------------------+--------------+-----+--------------------+------------------+------------------+---------------+---------------+---------------+--------------------+-------------------+----------------------+-----------------+----------------------+---------------+--------------------+--------------------+-------------+-------------+--------------------+--------------+--------------------+-----+--------+---------+-------------+------------------------+\n",
      "|0x4065fd476208a27...|Chiderah Abani|     5|null|Love, love, love....|1528890236792|11208554345809883...|New York Kim-Bob ...|       4.3|[Korean restauran...|       null|[[Monday, 7AM–9PM...|40.764643199999995|-73.81192399999999|New York Kim-Bob ...|            68|    $|[0x89c2602e5c9513...|Closed ⋅ Opens 7AM|              null|           null|[Good for kids]| [Casual, Cozy]|[College students...|               null|                  null|             null|                  null|           null|                null|[Comfort food, He...|         null|         null|[Lunch, Dinner, S...|          null|[Delivery, Takeou...|11354|Flushing|       NY|Queens County|                   51190|\n",
      "|0x4065fd476208a27...|  luis cabrera|     5|null|My favorite Kimba...|1589581105858|11034451447099652...|New York Kim-Bob ...|       4.3|[Korean restauran...|       null|[[Monday, 7AM–9PM...|40.764643199999995|-73.81192399999999|New York Kim-Bob ...|            68|    $|[0x89c2602e5c9513...|Closed ⋅ Opens 7AM|              null|           null|[Good for kids]| [Casual, Cozy]|[College students...|               null|                  null|             null|                  null|           null|                null|[Comfort food, He...|         null|         null|[Lunch, Dinner, S...|          null|[Delivery, Takeou...|11354|Flushing|       NY|Queens County|                   51190|\n",
      "|0x4065fd476208a27...|     SUNG CHOI|     5|null|                null|1485139260721|10431700601085267...|New York Kim-Bob ...|       4.3|[Korean restauran...|       null|[[Monday, 7AM–9PM...|40.764643199999995|-73.81192399999999|New York Kim-Bob ...|            68|    $|[0x89c2602e5c9513...|Closed ⋅ Opens 7AM|              null|           null|[Good for kids]| [Casual, Cozy]|[College students...|               null|                  null|             null|                  null|           null|                null|[Comfort food, He...|         null|         null|[Lunch, Dinner, S...|          null|[Delivery, Takeou...|11354|Flushing|       NY|Queens County|                   51190|\n",
      "+--------------------+--------------+------+----+--------------------+-------------+--------------------+--------------------+----------+--------------------+-----------+--------------------+------------------+------------------+--------------------+--------------+-----+--------------------+------------------+------------------+---------------+---------------+---------------+--------------------+-------------------+----------------------+-----------------+----------------------+---------------+--------------------+--------------------+-------------+-------------+--------------------+--------------+--------------------+-----+--------+---------+-------------+------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "combined_df = spark.read.parquet(\"gs://msca-bdp-student-gcs/Group_5_final_project/combined_rest_df/\") \n",
    "combined_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ac4e4cc-a9d8-4552-b5a5-756eb5c91e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when, col\n",
    "combined_df = combined_df.withColumn(\n",
    "    \"permanent_closed\",\n",
    "    when(col(\"state\").like(\"%Permanently closed%\"), 1).otherwise(0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "03b66a2c-f08a-472d-93be-a13e0299f082",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.types import ArrayType, StringType\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF, VectorAssembler\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54845a9f-5369-46d8-823d-c8e022294467",
   "metadata": {},
   "source": [
    "#### Most common tokens for restaurant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7040cee7-189e-418f-9593-ddddc5d9dc44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6858:====================================================> (43 + 1) / 44]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+\n",
      "|token     |count |\n",
      "+----------+------+\n",
      "|food      |431697|\n",
      "|great     |330406|\n",
      "|good      |305473|\n",
      "|place     |203824|\n",
      "|service   |173118|\n",
      "|like      |99338 |\n",
      "|best      |98113 |\n",
      "|nice      |92601 |\n",
      "|really    |85097 |\n",
      "|love      |84047 |\n",
      "|go        |81500 |\n",
      "|one       |78695 |\n",
      "|get       |76827 |\n",
      "|friendly  |75135 |\n",
      "|staff     |73305 |\n",
      "|time      |69861 |\n",
      "|always    |65960 |\n",
      "|delicious |64934 |\n",
      "|back      |61985 |\n",
      "|restaurant|60099 |\n",
      "|chicken   |58369 |\n",
      "|excellent |53132 |\n",
      "|pizza     |52727 |\n",
      "|order     |51318 |\n",
      "|also      |50503 |\n",
      "|even      |49435 |\n",
      "|little    |48366 |\n",
      "|ordered   |48013 |\n",
      "|definitely|47579 |\n",
      "|got       |47344 |\n",
      "|amazing   |45921 |\n",
      "|never     |45329 |\n",
      "|eat       |43611 |\n",
      "|come      |43357 |\n",
      "|try       |42644 |\n",
      "|recommend |41082 |\n",
      "|us        |40773 |\n",
      "|fresh     |39197 |\n",
      "|came      |38897 |\n",
      "|menu      |38123 |\n",
      "|went      |36914 |\n",
      "|people    |35815 |\n",
      "|first     |33765 |\n",
      "|pretty    |33491 |\n",
      "|well      |33152 |\n",
      "|made      |33033 |\n",
      "|awesome   |32877 |\n",
      "|ever      |32212 |\n",
      "|make      |32178 |\n",
      "|everything|31872 |\n",
      "+----------+------+\n",
      "only showing top 50 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Filter reviews for closed stores\n",
    "closed_reviews = english_df.filter(F.col(\"permanent_closed\") == 1)\n",
    "\n",
    "# Explode english_tokens into separate rows\n",
    "closed_tokens = closed_reviews.select(F.explode(F.col(\"english_tokens\")).alias(\"token\"))\n",
    "\n",
    "# Count token frequency\n",
    "closed_token_counts = closed_tokens.groupBy(\"token\").count().orderBy(F.desc(\"count\"))\n",
    "\n",
    "# Show top 20 most common tokens\n",
    "closed_token_counts.show(50, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f2996c-5ea0-4197-93df-f17b28d46c49",
   "metadata": {},
   "source": [
    "#### log-odds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2a4171b7-5fb2-441c-a8b8-d0e47eeff479",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import ArrayType, StringType\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover\n",
    "\n",
    "# ----------------------------\n",
    "# 1. Keep only rows where both text and rating are not null\n",
    "# ----------------------------\n",
    "combined_df_text = combined_df.filter(\n",
    "    (F.col(\"text\").isNotNull()) & \n",
    "    (F.col(\"rating\").isNotNull())\n",
    ")\n",
    "\n",
    "# ----------------------------\n",
    "# 2. Tokenize\n",
    "# ----------------------------\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"tokens\")\n",
    "tokenized_df = tokenizer.transform(combined_df_text)\n",
    "\n",
    "# ----------------------------\n",
    "# 3. Remove stop words\n",
    "# ----------------------------\n",
    "stop_remover = StopWordsRemover(inputCol=\"tokens\", outputCol=\"tokens_clean\")\n",
    "clean_df = stop_remover.transform(tokenized_df)\n",
    "\n",
    "# ----------------------------\n",
    "# 4. Keep only English tokens\n",
    "# ----------------------------\n",
    "english_udf = F.udf(\n",
    "    lambda tokens: [t.lower() for t in tokens if re.fullmatch(r\"[a-zA-Z]+\", t)],\n",
    "    ArrayType(StringType())\n",
    ")\n",
    "\n",
    "english_df = clean_df.withColumn(\"english_tokens\", english_udf(F.col(\"tokens_clean\")))\n",
    "\n",
    "# ----------------------------\n",
    "# 5. Filter closed and open stores\n",
    "# ----------------------------\n",
    "closed_df = english_df.filter(F.col(\"permanent_closed\") == 1)\n",
    "open_df = english_df.filter(F.col(\"permanent_closed\") == 0)\n",
    "\n",
    "# ----------------------------\n",
    "# 6. Explode tokens into single rows\n",
    "# ----------------------------\n",
    "closed_tokens = closed_df.select(F.explode(F.col(\"english_tokens\")).alias(\"token\"))\n",
    "open_tokens = open_df.select(F.explode(F.col(\"english_tokens\")).alias(\"token\"))\n",
    "\n",
    "# ----------------------------\n",
    "# 7. Count token occurrences\n",
    "# ----------------------------\n",
    "closed_counts = closed_tokens.groupBy(\"token\").count().withColumnRenamed(\"count\", \"closed_count\")\n",
    "open_counts = open_tokens.groupBy(\"token\").count().withColumnRenamed(\"count\", \"open_count\")\n",
    "\n",
    "# ----------------------------\n",
    "# 8. Merge counts and compute log-odds ratio\n",
    "# ----------------------------\n",
    "token_stats = closed_counts.join(open_counts, on=\"token\", how=\"outer\").fillna(0)\n",
    "token_stats = token_stats.withColumn(\n",
    "    \"log_odds_ratio\",\n",
    "    F.log( (F.col(\"closed_count\") + 1) / (F.col(\"open_count\") + 1) )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5115eac6-a133-4b31-b95d-ea396dedabde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+----------+------------------+\n",
      "|token     |closed_count|open_count|log_odds_ratio    |\n",
      "+----------+------------+----------+------------------+\n",
      "|zume      |28          |0         |3.367295829986474 |\n",
      "|cruffins  |83          |2         |3.332204510175204 |\n",
      "|baconslut |21          |0         |3.091042453358316 |\n",
      "|hopcat    |20          |0         |3.044522437723423 |\n",
      "|slyder    |17          |0         |2.8903717578961645|\n",
      "|cocotero  |16          |0         |2.833213344056216 |\n",
      "|lallisse  |15          |0         |2.772588722239781 |\n",
      "|brezo     |15          |0         |2.772588722239781 |\n",
      "|nellcote  |15          |0         |2.772588722239781 |\n",
      "|tondaku   |14          |0         |2.70805020110221  |\n",
      "|wildfox   |13          |0         |2.6390573296152584|\n",
      "|burritt   |13          |0         |2.6390573296152584|\n",
      "|cardoz    |13          |0         |2.6390573296152584|\n",
      "|fifolet   |12          |0         |2.5649493574615367|\n",
      "|duidough  |12          |0         |2.5649493574615367|\n",
      "|kkochi    |11          |0         |2.4849066497880004|\n",
      "|slidebar  |11          |0         |2.4849066497880004|\n",
      "|poang     |11          |0         |2.4849066497880004|\n",
      "|gulluoglu |11          |0         |2.4849066497880004|\n",
      "|abaleh    |11          |0         |2.4849066497880004|\n",
      "|azuri     |11          |0         |2.4849066497880004|\n",
      "|trelawni  |11          |0         |2.4849066497880004|\n",
      "|koroni    |10          |0         |2.3978952727983707|\n",
      "|nagao     |10          |0         |2.3978952727983707|\n",
      "|steinhof  |10          |0         |2.3978952727983707|\n",
      "|foldie    |10          |0         |2.3978952727983707|\n",
      "|lucienne  |10          |0         |2.3978952727983707|\n",
      "|rakken    |10          |0         |2.3978952727983707|\n",
      "|maysville |10          |0         |2.3978952727983707|\n",
      "|champps   |10          |0         |2.3978952727983707|\n",
      "|porsena   |10          |0         |2.3978952727983707|\n",
      "|yebisu    |10          |0         |2.3978952727983707|\n",
      "|cremia    |9           |0         |2.302585092994046 |\n",
      "|beerfish  |9           |0         |2.302585092994046 |\n",
      "|franchino |9           |0         |2.302585092994046 |\n",
      "|timna     |9           |0         |2.302585092994046 |\n",
      "|bajaj     |19          |1         |2.302585092994046 |\n",
      "|telepan   |9           |0         |2.302585092994046 |\n",
      "|andanada  |9           |0         |2.302585092994046 |\n",
      "|zabrosura |9           |0         |2.302585092994046 |\n",
      "|maradentro|9           |0         |2.302585092994046 |\n",
      "|kinfork   |9           |0         |2.302585092994046 |\n",
      "|tabun     |18          |1         |2.2512917986064953|\n",
      "|mahila    |8           |0         |2.1972245773362196|\n",
      "|ichiba    |8           |0         |2.1972245773362196|\n",
      "|zapatista |8           |0         |2.1972245773362196|\n",
      "|boru      |17          |1         |2.1972245773362196|\n",
      "|lacreasia |8           |0         |2.1972245773362196|\n",
      "|leonti    |17          |1         |2.1972245773362196|\n",
      "|bisou     |26          |2         |2.1972245773362196|\n",
      "+----------+------------+----------+------------------+\n",
      "only showing top 50 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6854:====================================================> (43 + 1) / 44]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------------+----------+-------------------+\n",
      "|token          |closed_count|open_count|log_odds_ratio     |\n",
      "+---------------+------------+----------+-------------------+\n",
      "|mcgriddle      |0           |888       |-6.790097235513905 |\n",
      "|venti          |3           |2852      |-6.5698319900936095|\n",
      "|playplace      |0           |706       |-6.561030665896573 |\n",
      "|bussin         |0           |529       |-6.272877006546167 |\n",
      "|whoppers       |4           |2584      |-6.248042874508429 |\n",
      "|jitb           |0           |504       |-6.22455842927536  |\n",
      "|casinos        |2           |1489      |-6.207919110271395 |\n",
      "|mcmuffins      |1           |968       |-6.183117431330821 |\n",
      "|pizookie       |0           |474       |-6.163314804034641 |\n",
      "|culvers        |2           |1410      |-6.153441663184704 |\n",
      "|mcgriddles     |0           |442       |-6.093569770045136 |\n",
      "|frape          |0           |430       |-6.066108090103747 |\n",
      "|distancing     |30          |12672     |-6.013241820596918 |\n",
      "|bolillo        |0           |383       |-5.950642552587727 |\n",
      "|mcmuffin       |7           |3037      |-5.939513141475882 |\n",
      "|payouts        |0           |372       |-5.921578419643816 |\n",
      "|malnati        |0           |366       |-5.905361848054571 |\n",
      "|starbuck       |2           |1083      |-5.889800893331482 |\n",
      "|frappuccino    |7           |2887      |-5.8888779583328805|\n",
      "|ventanilla     |0           |354       |-5.872117789475416 |\n",
      "|mcchicken      |5           |1895      |-5.755742213586912 |\n",
      "|bowlero        |0           |310       |-5.739792912179234 |\n",
      "|yury           |0           |301       |-5.71042701737487  |\n",
      "|chambre        |0           |295       |-5.69035945432406  |\n",
      "|filas          |0           |290       |-5.673323267171493 |\n",
      "|distanced      |6           |2003      |-5.656990313149442 |\n",
      "|drivethru      |7           |2288      |-5.656428778272731 |\n",
      "|whopper        |30          |8485      |-5.612185821277124 |\n",
      "|escalators     |0           |272       |-5.60947179518496  |\n",
      "|machetes       |0           |269       |-5.598421958998375 |\n",
      "|wopper         |0           |269       |-5.598421958998375 |\n",
      "|frosties       |2           |799       |-5.585999438999818 |\n",
      "|twa            |0           |265       |-5.583496308781699 |\n",
      "|keno           |0           |265       |-5.583496308781699 |\n",
      "|plexiglass     |2           |788       |-5.572154032177765 |\n",
      "|shamrock       |3           |1051      |-5.572154032177765 |\n",
      "|mcdonals       |1           |518       |-5.558756702605943 |\n",
      "|sanders        |0           |258       |-5.556828061699537 |\n",
      "|otay           |0           |258       |-5.556828061699537 |\n",
      "|jacuzzi        |1           |510       |-5.543222409643759 |\n",
      "|frapps         |0           |254       |-5.541263545158426 |\n",
      "|divierten      |0           |253       |-5.537334267018537 |\n",
      "|slopes         |1           |503       |-5.529429087511423 |\n",
      "|complying      |0           |249       |-5.521460917862246 |\n",
      "|mccafe         |1           |495       |-5.5134287461649825|\n",
      "|distanciamiento|0           |245       |-5.5053315359323625|\n",
      "|mcflurry       |5           |1472      |-5.503296947234575 |\n",
      "|unmasked       |0           |242       |-5.493061443340548 |\n",
      "|boucherie      |0           |242       |-5.493061443340548 |\n",
      "|mcdoubles      |2           |715       |-5.475067878292536 |\n",
      "+---------------+------------+----------+-------------------+\n",
      "only showing top 50 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# 9. Sort by most indicative tokens for closure\n",
    "# ----------------------------\n",
    "top_tokens_closed = token_stats.orderBy(F.col(\"log_odds_ratio\").desc())\n",
    "top_tokens_closed.show(50, truncate=False)\n",
    "\n",
    "# ----------------------------\n",
    "# 10. Optionally, sort for tokens indicative of open stores\n",
    "# ----------------------------\n",
    "top_tokens_open = token_stats.orderBy(F.col(\"log_odds_ratio\").asc())\n",
    "top_tokens_open.show(50, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62455b34-321e-4f25-bfc4-2c53ddde8bd2",
   "metadata": {},
   "source": [
    "#### Top N-grams (phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "728fc6aa-cc4f-423d-aa70-7ddb4a1db081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " TOP CLOSURE BIGRAMS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------+----------+------------------+\n",
      "|ngram              |closed_count|open_count|log_odds_ratio    |\n",
      "+-------------------+------------+----------+------------------+\n",
      "|little bucharest   |32          |0         |3.4965075614664802|\n",
      "|hu kitchen         |24          |0         |3.2188758248682006|\n",
      "|lunar blossom      |20          |0         |3.044522437723423 |\n",
      "|viper alley        |19          |0         |2.995732273553991 |\n",
      "|bar agricole       |18          |0         |2.9444389791664403|\n",
      "|mumbai tandoor     |37          |1         |2.9444389791664403|\n",
      "|scammers scammers  |56          |2         |2.9444389791664403|\n",
      "|bombay bread       |18          |0         |2.9444389791664403|\n",
      "|firefly grill      |18          |0         |2.9444389791664403|\n",
      "|la tabun           |17          |0         |2.8903717578961645|\n",
      "|top wok            |15          |0         |2.772588722239781 |\n",
      "|ringer hut         |14          |0         |2.70805020110221  |\n",
      "|cafe clover        |13          |0         |2.6390573296152584|\n",
      "|fedora burger      |13          |0         |2.6390573296152584|\n",
      "|ihop express       |13          |0         |2.6390573296152584|\n",
      "|chef gator         |12          |0         |2.5649493574615367|\n",
      "|seven lions        |12          |0         |2.5649493574615367|\n",
      "|cafe rolle         |12          |0         |2.5649493574615367|\n",
      "|cultivation kitchen|12          |0         |2.5649493574615367|\n",
      "|clever rabbit      |11          |0         |2.4849066497880004|\n",
      "|zume pizza         |11          |0         |2.4849066497880004|\n",
      "|kirin buffet       |11          |0         |2.4849066497880004|\n",
      "|gau poang          |11          |0         |2.4849066497880004|\n",
      "|phelps hotel       |11          |0         |2.4849066497880004|\n",
      "|southern cut       |22          |1         |2.4423470353692043|\n",
      "|fin inn            |10          |0         |2.3978952727983707|\n",
      "|el cocotero        |10          |0         |2.3978952727983707|\n",
      "|kachori pizza      |10          |0         |2.3978952727983707|\n",
      "|pasta flyer        |10          |0         |2.3978952727983707|\n",
      "|stock trade        |10          |0         |2.3978952727983707|\n",
      "|tuscan tavern      |10          |0         |2.3978952727983707|\n",
      "|baconslut sandwich |10          |0         |2.3978952727983707|\n",
      "|roti buns          |10          |0         |2.3978952727983707|\n",
      "|saint rocke        |10          |0         |2.3978952727983707|\n",
      "|chez lucienne      |10          |0         |2.3978952727983707|\n",
      "|tacos ink          |10          |0         |2.3978952727983707|\n",
      "|cafe chloe         |10          |0         |2.3978952727983707|\n",
      "|bisou bisou        |9           |0         |2.302585092994046 |\n",
      "|zen express        |9           |0         |2.302585092994046 |\n",
      "|tommy lasagna      |9           |0         |2.302585092994046 |\n",
      "|corso como         |9           |0         |2.302585092994046 |\n",
      "|eun ji             |9           |0         |2.302585092994046 |\n",
      "|filipino vegan     |9           |0         |2.302585092994046 |\n",
      "|jupiter hall       |9           |0         |2.302585092994046 |\n",
      "|belly cotton       |9           |0         |2.302585092994046 |\n",
      "|southbound bbq     |9           |0         |2.302585092994046 |\n",
      "|bucharest bistro   |9           |0         |2.302585092994046 |\n",
      "|muk eun            |9           |0         |2.302585092994046 |\n",
      "|royal cut          |9           |0         |2.302585092994046 |\n",
      "|la urbana          |9           |0         |2.302585092994046 |\n",
      "+-------------------+------------+----------+------------------+\n",
      "only showing top 50 rows\n",
      "\n",
      "\n",
      " TOP CLOSURE TRIGRAMS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------+------------+----------+------------------+\n",
      "|ngram                              |closed_count|open_count|log_odds_ratio    |\n",
      "+-----------------------------------+------------+----------+------------------+\n",
      "|scammers scammers scammers         |55          |0         |4.02535169073515  |\n",
      "|lincoln square steak               |18          |0         |2.9444389791664403|\n",
      "|fluffy fluffy fluffy               |17          |0         |2.8903717578961645|\n",
      "|uuuuu uuuuu uuuuu                  |16          |0         |2.833213344056216 |\n",
      "|chilaquiles chilaquiles chilaquiles|16          |0         |2.833213344056216 |\n",
      "|tell traditional burgers           |15          |0         |2.772588722239781 |\n",
      "|bombay bread bar                   |14          |0         |2.70805020110221  |\n",
      "|best tell traditional              |13          |0         |2.6390573296152584|\n",
      "|mozzarella bar pizza               |13          |0         |2.6390573296152584|\n",
      "|bar pizza e                        |12          |0         |2.5649493574615367|\n",
      "|kitchen bar downtown               |11          |0         |2.4849066497880004|\n",
      "|crab artichoke sandwich            |10          |0         |2.3978952727983707|\n",
      "|beach street grill                 |10          |0         |2.3978952727983707|\n",
      "|wrapped brisket bites              |9           |0         |2.302585092994046 |\n",
      "|seaweed sushi roll                 |9           |0         |2.302585092994046 |\n",
      "|bacon wrapped brisket              |9           |0         |2.302585092994046 |\n",
      "|pork belly cotton                  |8           |0         |2.1972245773362196|\n",
      "|ron swanson themed                 |8           |0         |2.1972245773362196|\n",
      "|muk eun ji                         |8           |0         |2.1972245773362196|\n",
      "|old boy burrito                    |8           |0         |2.1972245773362196|\n",
      "|little bucharest bistro            |8           |0         |2.1972245773362196|\n",
      "|pang fried noodles                 |8           |0         |2.1972245773362196|\n",
      "|best bad bargain                   |8           |0         |2.1972245773362196|\n",
      "|nice one bakery                    |8           |0         |2.1972245773362196|\n",
      "|south central fries                |7           |0         |2.0794415416798357|\n",
      "|got baked san                      |7           |0         |2.0794415416798357|\n",
      "|combination xiao long              |7           |0         |2.0794415416798357|\n",
      "|chopped chile tacos                |7           |0         |2.0794415416798357|\n",
      "|south troy burger                  |7           |0         |2.0794415416798357|\n",
      "|burger arts district               |7           |0         |2.0794415416798357|\n",
      "|foie gras soup                     |7           |0         |2.0794415416798357|\n",
      "|cafe di roma                       |7           |0         |2.0794415416798357|\n",
      "|patzeria family friends            |7           |0         |2.0794415416798357|\n",
      "|van restaurant vietnamese          |7           |0         |2.0794415416798357|\n",
      "|umami burger arts                  |7           |0         |2.0794415416798357|\n",
      "|oh wa la                           |6           |0         |1.9459101490553132|\n",
      "|royal rib house                    |6           |0         |1.9459101490553132|\n",
      "|fat city sandwich                  |6           |0         |1.9459101490553132|\n",
      "|springfield char house             |6           |0         |1.9459101490553132|\n",
      "|southwestern chicken melt          |6           |0         |1.9459101490553132|\n",
      "|apple baked beans                  |6           |0         |1.9459101490553132|\n",
      "|sweetie pies noho                  |6           |0         |1.9459101490553132|\n",
      "|table talk diner                   |6           |0         |1.9459101490553132|\n",
      "|queens beer house                  |6           |0         |1.9459101490553132|\n",
      "|hacienda de vega                   |6           |0         |1.9459101490553132|\n",
      "|solace moonlight lounge            |6           |0         |1.9459101490553132|\n",
      "|scissor cut noodles                |6           |0         |1.9459101490553132|\n",
      "|new century lobster                |6           |0         |1.9459101490553132|\n",
      "|la best restaurant                 |47          |6         |1.9252908618525777|\n",
      "|burgers best tell                  |12          |1         |1.8718021769015913|\n",
      "+-----------------------------------+------------+----------+------------------+\n",
      "only showing top 50 rows\n",
      "\n",
      "\n",
      " TOP OPEN-STORE BIGRAMS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------+----------+-------------------+\n",
      "|ngram              |closed_count|open_count|log_odds_ratio     |\n",
      "+-------------------+------------+----------+-------------------+\n",
      "|love starbucks     |1           |4498      |-7.718463248281227 |\n",
      "|favorite starbucks |0           |1775      |-7.4821189235521155|\n",
      "|good stores        |0           |1299      |-7.170119543449628 |\n",
      "|starbucks ever     |1           |2536      |-7.145590379039336 |\n",
      "|worst starbucks    |1           |2358      |-7.07284589884773  |\n",
      "|lines drive        |0           |1036      |-6.9440872082295275|\n",
      "|slowest starbucks  |0           |1012      |-6.920671504248683 |\n",
      "|double animal      |1           |1787      |-6.795705775173515 |\n",
      "|sausage mcmuffin   |0           |870       |-6.769641976852503 |\n",
      "|best starbucks     |3           |3252      |-6.7010385653534605|\n",
      "|use mobile         |0           |795       |-6.679599185844383 |\n",
      "|nice mall          |2           |2360      |-6.668228248417403 |\n",
      "|another starbucks  |0           |779       |-6.659293919683638 |\n",
      "|standard starbucks |0           |778       |-6.658011045870748 |\n",
      "|animal style       |10          |8016      |-6.591424293244581 |\n",
      "|spicy nuggets      |0           |699       |-6.551080335043404 |\n",
      "|stores shop        |0           |690       |-6.53813982376767  |\n",
      "|every starbucks    |0           |679       |-6.522092798170153 |\n",
      "|love mc            |0           |668       |-6.505784060128228 |\n",
      "|thru fast          |2           |1951      |-6.477997478304928 |\n",
      "|sat line           |0           |642       |-6.466144724237619 |\n",
      "|hot tub            |0           |642       |-6.466144724237619 |\n",
      "|nice casino        |0           |640       |-6.46302945692067  |\n",
      "|starbucks great    |1           |1268      |-6.452837287154442 |\n",
      "|love cracker       |0           |631       |-6.448889394146858 |\n",
      "|starbucks starbucks|0           |618       |-6.428105272684596 |\n",
      "|places shop        |0           |589       |-6.380122536899766 |\n",
      "|thru line          |12          |7668      |-6.379992150303322 |\n",
      "|extra caramel      |0           |585       |-6.373319789577012 |\n",
      "|variety stores     |2           |1722      |-6.35320994785982  |\n",
      "|big mall           |0           |570       |-6.3473892096560105|\n",
      "|love sonic         |0           |570       |-6.3473892096560105|\n",
      "|mobile order       |10          |6132      |-6.323544032827614 |\n",
      "|line drive         |8           |5004      |-6.320968114413102 |\n",
      "|selection stores   |1           |1104      |-6.314453433391908 |\n",
      "|good starbucks     |1           |1087      |-6.298949246855942 |\n",
      "|piece nuggets      |0           |541       |-6.295266001439646 |\n",
      "|new stores         |0           |538       |-6.289715570908998 |\n",
      "|faster drive       |0           |537       |-6.2878585601617845|\n",
      "|best casino        |0           |535       |-6.284134161070802 |\n",
      "|love mall          |1           |1067      |-6.280395838960195 |\n",
      "|mocha frappe       |0           |532       |-6.278521424165844 |\n",
      "|worst mcdonalds    |2           |1542      |-6.242871563695051 |\n",
      "|sourdough jack     |0           |512       |-6.240275845170769 |\n",
      "|double double      |11          |6114      |-6.233593398333272 |\n",
      "|come starbucks     |0           |508       |-6.2324480165505225|\n",
      "|box ever           |0           |501       |-6.218600119691729 |\n",
      "|good jack          |0           |500       |-6.2166061010848646|\n",
      "|covid safety       |1           |993       |-6.208590026096629 |\n",
      "|great mall         |3           |1973      |-6.2015228588735365|\n",
      "+-------------------+------------+----------+-------------------+\n",
      "only showing top 50 rows\n",
      "\n",
      "\n",
      " TOP OPEN-STORE TRIGRAMS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6880:========================================>            (51 + 16) / 67]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+------------+----------+-------------------+\n",
      "|ngram                     |closed_count|open_count|log_odds_ratio     |\n",
      "+--------------------------+------------+----------+-------------------+\n",
      "|long line drive           |0           |1633      |-7.3987862754199485|\n",
      "|love jack box             |0           |937       |-6.843749949006225 |\n",
      "|worst starbucks ever      |0           |808       |-6.695798917058492 |\n",
      "|double double animal      |1           |1545      |-6.6502790485874215|\n",
      "|drive thru line           |9           |7400      |-6.606785312203421 |\n",
      "|quick drive thru          |1           |1472      |-6.601909235902685 |\n",
      "|drive thru never          |0           |688       |-6.535241271013659 |\n",
      "|long lines drive          |0           |643       |-6.467698726104354 |\n",
      "|drive thru fast           |2           |1883      |-6.4425401664681985|\n",
      "|go wrong n                |0           |605       |-6.406879986069314 |\n",
      "|employees wearing masks   |0           |579       |-6.363028103540465 |\n",
      "|animal style fries        |2           |1697      |-6.338594078203183 |\n",
      "|thru line long            |0           |541       |-6.295266001439646 |\n",
      "|worst mcdonalds ever      |0           |533       |-6.280395838960195 |\n",
      "|curb side pick            |0           |523       |-6.261491684321042 |\n",
      "|slow service drive        |0           |520       |-6.255750041753367 |\n",
      "|double animal style       |1           |1039      |-6.253828811575473 |\n",
      "|jack box always           |0           |503       |-6.222576268071369 |\n",
      "|person drive thru         |0           |502       |-6.220590170099739 |\n",
      "|drive thru moves          |0           |473       |-6.161207321695077 |\n",
      "|long drive thru           |5           |2783      |-6.139884552226255 |\n",
      "|hour drive thru           |0           |459       |-6.131226489483141 |\n",
      "|horrible drive thru       |0           |456       |-6.124683390894205 |\n",
      "|quarter pounder cheese    |1           |892       |-6.101439400316554 |\n",
      "|lines drive thru          |0           |443       |-6.095824562432225 |\n",
      "|lemonade lemonade lemonade|0           |438       |-6.0844994130751715|\n",
      "|jack box ever             |0           |431       |-6.068425588244111 |\n",
      "|love animal style         |0           |422       |-6.0473721790462776|\n",
      "|car drive thru            |0           |418       |-6.037870919922137 |\n",
      "|sausage egg mcmuffin      |0           |404       |-6.003887067106539 |\n",
      "|slowest starbucks ever    |0           |401       |-5.996452088619021 |\n",
      "|forget something order    |0           |399       |-5.991464547107982 |\n",
      "|animal style burger       |0           |397       |-5.986452005284438 |\n",
      "|great social distancing   |0           |392       |-5.973809611869261 |\n",
      "|drive thru parking        |0           |391       |-5.971261839790462 |\n",
      "|las mejores carnitas      |0           |391       |-5.971261839790462 |\n",
      "|drive thru pretty         |1           |779       |-5.966146739123692 |\n",
      "|nice place shop           |1           |770       |-5.954541193003385 |\n",
      "|line long moved           |0           |375       |-5.929589143389895 |\n",
      "|spent minutes drive       |0           |369       |-5.91350300563827  |\n",
      "|muy ricas hamburguesas    |0           |364       |-5.8998973535824915|\n",
      "|lolol lolol lolol         |0           |363       |-5.8971538676367405|\n",
      "|wait time drive           |1           |726       |-5.895779296973574 |\n",
      "|love ice coffee           |0           |360       |-5.8888779583328805|\n",
      "|use mobile app            |0           |359       |-5.886104031450156 |\n",
      "|love double double        |0           |357       |-5.8805329864007   |\n",
      "|drive thru packed         |0           |352       |-5.8664680569332965|\n",
      "|one favorite starbucks    |0           |351       |-5.863631175598097 |\n",
      "|best starbucks ever       |0           |347       |-5.8522024797744745|\n",
      "|drive thru always         |10          |3816      |-5.849324779946859 |\n",
      "+--------------------------+------------+----------+-------------------+\n",
      "only showing top 50 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import NGram\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 1. Create bigrams & trigrams from english_tokens\n",
    "# -------------------------------------------------\n",
    "bigrammer = NGram(n=2, inputCol=\"english_tokens\", outputCol=\"bigrams\")\n",
    "trigrammer = NGram(n=3, inputCol=\"english_tokens\", outputCol=\"trigrams\")\n",
    "\n",
    "df_with_bigrams = bigrammer.transform(english_df)\n",
    "df_with_ngrams = trigrammer.transform(df_with_bigrams)\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 2. Filter open vs closed stores\n",
    "# -------------------------------------------------\n",
    "closed_ngram_df = df_with_ngrams.filter(F.col(\"permanent_closed\") == 1)\n",
    "open_ngram_df   = df_with_ngrams.filter(F.col(\"permanent_closed\") == 0)\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 3. Explode bigrams & trigrams\n",
    "# -------------------------------------------------\n",
    "closed_bigrams = closed_ngram_df.select(F.explode(F.col(\"bigrams\")).alias(\"ngram\"))\n",
    "open_bigrams   = open_ngram_df.select(F.explode(F.col(\"bigrams\")).alias(\"ngram\"))\n",
    "\n",
    "closed_trigrams = closed_ngram_df.select(F.explode(F.col(\"trigrams\")).alias(\"ngram\"))\n",
    "open_trigrams   = open_ngram_df.select(F.explode(F.col(\"trigrams\")).alias(\"ngram\"))\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 4. Count n-grams\n",
    "# -------------------------------------------------\n",
    "closed_bigram_counts = closed_bigrams.groupBy(\"ngram\").count().withColumnRenamed(\"count\", \"closed_count\")\n",
    "open_bigram_counts   = open_bigrams.groupBy(\"ngram\").count().withColumnRenamed(\"count\", \"open_count\")\n",
    "\n",
    "closed_trigram_counts = closed_trigrams.groupBy(\"ngram\").count().withColumnRenamed(\"count\", \"closed_count\")\n",
    "open_trigram_counts   = open_trigrams.groupBy(\"ngram\").count().withColumnRenamed(\"count\", \"open_count\")\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 5. Compute log odds ratio (like token analysis)\n",
    "# -------------------------------------------------\n",
    "def compute_stats(closed_df, open_df):\n",
    "    stats = closed_df.join(open_df, on=\"ngram\", how=\"outer\").fillna(0)\n",
    "    stats = stats.withColumn(\n",
    "        \"log_odds_ratio\",\n",
    "        F.log((F.col(\"closed_count\") + 1) / (F.col(\"open_count\") + 1))\n",
    "    )\n",
    "    return stats\n",
    "\n",
    "bigram_stats  = compute_stats(closed_bigram_counts, open_bigram_counts)\n",
    "trigram_stats = compute_stats(closed_trigram_counts, open_trigram_counts)\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 6. Rank n-grams most indicative of closed stores\n",
    "# -------------------------------------------------\n",
    "top_bigrams_closed = bigram_stats.orderBy(F.col(\"log_odds_ratio\").desc())\n",
    "top_trigrams_closed = trigram_stats.orderBy(F.col(\"log_odds_ratio\").desc())\n",
    "\n",
    "print(\"\\n TOP CLOSURE BIGRAMS\")\n",
    "top_bigrams_closed.show(50, truncate=False)\n",
    "\n",
    "print(\"\\n TOP CLOSURE TRIGRAMS\")\n",
    "top_trigrams_closed.show(50, truncate=False)\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 7. Also rank open-store ngrams (healthy indicators)\n",
    "# -------------------------------------------------\n",
    "top_bigrams_open = bigram_stats.orderBy(F.col(\"log_odds_ratio\").asc())\n",
    "top_trigrams_open = trigram_stats.orderBy(F.col(\"log_odds_ratio\").asc())\n",
    "\n",
    "print(\"\\n TOP OPEN-STORE BIGRAMS\")\n",
    "top_bigrams_open.show(50, truncate=False)\n",
    "\n",
    "print(\"\\n TOP OPEN-STORE TRIGRAMS\")\n",
    "top_trigrams_open.show(50, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce53e803-d045-4053-9653-103910064c67",
   "metadata": {},
   "source": [
    "#### remove store name top n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f3dc63bb-911e-4e2e-8aa6-a391ee6b6d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, NGram\n",
    "\n",
    "# ----------------------------\n",
    "# 1. Keep only reviews from permanently closed stores\n",
    "# ----------------------------\n",
    "closed_df = combined_df.filter(\n",
    "    (F.col(\"text\").isNotNull()) &\n",
    "    (F.col(\"rating\").isNotNull()) &\n",
    "    (F.col(\"permanent_closed\") == 1)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2e56eae1-1bce-469a-86d5-bf829283ca62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1188577"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closed_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c3780463-e6af-4772-8b3b-ad73ed224e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6887:===================================================>  (42 + 2) / 44]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------+------------+\n",
      "|ngram                        |closed_count|\n",
      "+-----------------------------+------------+\n",
      "|highly recommend anyone      |376         |\n",
      "|definitely recommend anyone  |264         |\n",
      "|highly recommend try         |208         |\n",
      "|decided give try             |199         |\n",
      "|ordered took minutes         |179         |\n",
      "|highly recommend trying      |168         |\n",
      "|highly recommend going       |165         |\n",
      "|customer highly recommend    |157         |\n",
      "|definitely highly recommend  |145         |\n",
      "|recommend anyone wants       |143         |\n",
      "|highly recommend definitely  |128         |\n",
      "|loved highly recommend       |124         |\n",
      "|took almost minutes          |103         |\n",
      "|highly recommend checking    |102         |\n",
      "|definitely recommend trying  |100         |\n",
      "|definitely recommend try     |98          |\n",
      "|definitely going try         |96          |\n",
      "|waited minutes waitress      |93          |\n",
      "|try highly recommend         |92          |\n",
      "|took minutes bring           |91          |\n",
      "|reasonable highly recommend  |91          |\n",
      "|ordered waited minutes       |89          |\n",
      "|definitely recommend going   |89          |\n",
      "|took minutes ordered         |88          |\n",
      "|(translated google)          |87          |\n",
      "|waited almost minutes        |87          |\n",
      "|tried highly recommend       |86          |\n",
      "|highly recommend stopping    |85          |\n",
      "|asked waitress said          |85          |\n",
      "|enjoyed highly recommend     |83          |\n",
      "|loved definitely recommend   |80          |\n",
      "|ordered ordered ordered      |80          |\n",
      "|going highly recommend       |80          |\n",
      "|ordered highly recommend     |79          |\n",
      "|asked waiter said            |78          |\n",
      "|waited minutes someone       |78          |\n",
      "|took minutes waitress        |76          |\n",
      "|highly recommend give        |76          |\n",
      "|took minutes minutes         |75          |\n",
      "|said asked said              |75          |\n",
      "|waited minutes waiter        |75          |\n",
      "|asked said asked             |74          |\n",
      "|asked manager said           |74          |\n",
      "|                             |73          |\n",
      "|recommend anyone try         |72          |\n",
      "|customer definitely recommend|68          |\n",
      "|went waited minutes          |68          |\n",
      "|decided try ordered          |68          |\n",
      "|ordered husband ordered      |68          |\n",
      "|said said said               |68          |\n",
      "+-----------------------------+------------+\n",
      "only showing top 50 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import ArrayType, StringType\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, NGram\n",
    "\n",
    "# ----------------------------\n",
    "# 1. Keep only reviews from permanently closed stores\n",
    "# ----------------------------\n",
    "closed_df = combined_df.filter(\n",
    "    (F.col(\"text\").isNotNull()) &\n",
    "    (F.col(\"rating\").isNotNull()) &\n",
    "    (F.col(\"permanent_closed\") == 1)\n",
    ")\n",
    "\n",
    "# Optional: sample 1% for testing\n",
    "closed_df = closed_df.sample(fraction=1.0, seed=42)\n",
    "\n",
    "# ----------------------------\n",
    "# 2. Tokenize\n",
    "# ----------------------------\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"tokens\")\n",
    "closed_df = tokenizer.transform(closed_df)\n",
    "\n",
    "# ----------------------------\n",
    "# 3. Remove stopwords\n",
    "# ----------------------------\n",
    "stop_remover = StopWordsRemover(inputCol=\"tokens\", outputCol=\"tokens_clean\")\n",
    "closed_df = stop_remover.transform(closed_df)\n",
    "\n",
    "# ----------------------------\n",
    "# 4. Keep only alphabetic English tokens >= 3 chars\n",
    "# ----------------------------\n",
    "closed_df = closed_df.withColumn(\n",
    "    \"english_tokens\",\n",
    "    F.expr(\"filter(transform(tokens_clean, x -> lower(x)), x -> x rlike '^[a-z]{3,}$')\")\n",
    ")\n",
    "\n",
    "# ----------------------------\n",
    "# 5. Remove store name words using broadcast UDF\n",
    "# ----------------------------\n",
    "store_words_list = (\n",
    "    combined_df\n",
    "    .select(F.lower(F.col(\"store_name\")).alias(\"name\"))\n",
    "    .select(F.split(\"name\", \" \").alias(\"words\"))\n",
    "    .select(F.explode(\"words\").alias(\"w\"))\n",
    "    .filter(F.length(\"w\") > 2)\n",
    "    .distinct()\n",
    "    .rdd.flatMap(lambda x: x)\n",
    "    .collect()\n",
    ")\n",
    "\n",
    "broadcast_store_words = spark.sparkContext.broadcast(set(store_words_list))\n",
    "\n",
    "def remove_store_words(tokens):\n",
    "    return [t for t in tokens if t not in broadcast_store_words.value]\n",
    "\n",
    "remove_store_words_udf = F.udf(remove_store_words, ArrayType(StringType()))\n",
    "\n",
    "closed_df = closed_df.withColumn(\"operational_tokens\", remove_store_words_udf(\"english_tokens\"))\n",
    "\n",
    "# ----------------------------\n",
    "# 6. Create trigrams\n",
    "# ----------------------------\n",
    "trigrammer = NGram(n=3, inputCol=\"operational_tokens\", outputCol=\"trigrams\")\n",
    "closed_df = trigrammer.transform(closed_df)\n",
    "\n",
    "# ----------------------------\n",
    "# 7. Explode trigrams and count\n",
    "# ----------------------------\n",
    "trigram_exploded = closed_df.select(F.explode(\"trigrams\").alias(\"ngram\"))\n",
    "trigram_counts = trigram_exploded.groupBy(\"ngram\").count().withColumnRenamed(\"count\", \"closed_count\")\n",
    "\n",
    "# ----------------------------\n",
    "# 8. Rank trigrams by frequency\n",
    "# ----------------------------\n",
    "trigram_stats = trigram_counts.orderBy(F.col(\"closed_count\").desc())\n",
    "\n",
    "# ----------------------------\n",
    "# 9. Show top 50 trigrams\n",
    "# ----------------------------\n",
    "trigram_stats.show(50, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e1dd7783-7f3a-4cbe-a980-a200343f3569",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import ArrayType, StringType\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, NGram\n",
    "from functools import reduce\n",
    "\n",
    "# ----------------------------\n",
    "# 1. Filter closed and open store reviews\n",
    "# ----------------------------\n",
    "closed_df = combined_df.filter(\n",
    "    (F.col(\"text\").isNotNull()) &\n",
    "    (F.col(\"rating\").isNotNull()) &\n",
    "    (F.col(\"permanent_closed\") == 1)\n",
    ")\n",
    "\n",
    "open_df = combined_df.filter(\n",
    "    (F.col(\"text\").isNotNull()) &\n",
    "    (F.col(\"rating\").isNotNull()) &\n",
    "    (F.col(\"permanent_closed\") == 0)\n",
    ")\n",
    "\n",
    "# Optional: sample small fraction for testing\n",
    "closed_df = closed_df.sample(fraction=1.0, seed=42)\n",
    "open_df   = open_df.sample(fraction=1.0, seed=42)\n",
    "\n",
    "# ----------------------------\n",
    "# 2. Tokenize and remove stopwords\n",
    "# ----------------------------\n",
    "def clean_tokens(df):\n",
    "    tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"tokens\")\n",
    "    df = tokenizer.transform(df)\n",
    "\n",
    "    stop_remover = StopWordsRemover(inputCol=\"tokens\", outputCol=\"tokens_clean\")\n",
    "    df = stop_remover.transform(df)\n",
    "\n",
    "    # Keep only alphabetic English tokens >= 3 chars\n",
    "    df = df.withColumn(\n",
    "        \"english_tokens\",\n",
    "        F.expr(\"filter(transform(tokens_clean, x -> lower(x)), x -> x rlike '^[a-z]{3,}$')\")\n",
    "    )\n",
    "    return df\n",
    "\n",
    "closed_df = clean_tokens(closed_df)\n",
    "open_df   = clean_tokens(open_df)\n",
    "\n",
    "# ----------------------------\n",
    "# 3. Remove store name words using broadcast\n",
    "# ----------------------------\n",
    "store_words_list = (\n",
    "    combined_df\n",
    "    .select(F.lower(F.col(\"store_name\")).alias(\"name\"))\n",
    "    .select(F.split(\"name\", \" \").alias(\"words\"))\n",
    "    .select(F.explode(\"words\").alias(\"w\"))\n",
    "    .filter(F.length(\"w\") > 2)\n",
    "    .distinct()\n",
    "    .rdd.flatMap(lambda x: x)\n",
    "    .collect()\n",
    ")\n",
    "\n",
    "broadcast_store_words = spark.sparkContext.broadcast(set(store_words_list))\n",
    "\n",
    "def remove_store_words(tokens):\n",
    "    return [t for t in tokens if t not in broadcast_store_words.value]\n",
    "\n",
    "remove_store_words_udf = F.udf(remove_store_words, ArrayType(StringType()))\n",
    "\n",
    "closed_df = closed_df.withColumn(\"operational_tokens\", remove_store_words_udf(\"english_tokens\"))\n",
    "open_df   = open_df.withColumn(\"operational_tokens\", remove_store_words_udf(\"english_tokens\"))\n",
    "\n",
    "# ----------------------------\n",
    "# 4. Create trigrams\n",
    "# ----------------------------\n",
    "trigrammer = NGram(n=3, inputCol=\"operational_tokens\", outputCol=\"trigrams\")\n",
    "closed_df = trigrammer.transform(closed_df)\n",
    "open_df   = trigrammer.transform(open_df)\n",
    "\n",
    "# ----------------------------\n",
    "# 5. Explode trigrams and count\n",
    "# ----------------------------\n",
    "def trigram_count(df, count_col):\n",
    "    exploded = df.select(F.explode(\"trigrams\").alias(\"ngram\"))\n",
    "    return exploded.groupBy(\"ngram\").count().withColumnRenamed(\"count\", count_col)\n",
    "\n",
    "closed_counts = trigram_count(closed_df, \"closed_count\")\n",
    "open_counts   = trigram_count(open_df, \"open_count\")\n",
    "\n",
    "# ----------------------------\n",
    "# 6. Combine counts for comparison\n",
    "# ----------------------------\n",
    "combined_counts = closed_counts.join(open_counts, on=\"ngram\", how=\"outer\").fillna(0)\n",
    "\n",
    "# Compute log-odds ratio (positive = more frequent in closed stores)\n",
    "combined_counts = combined_counts.withColumn(\n",
    "    \"log_odds_ratio\",\n",
    "    F.log((F.col(\"closed_count\")+1)/(F.col(\"open_count\")+1))\n",
    ")\n",
    "\n",
    "# ----------------------------\n",
    "# 7. Rank trigrams for comparative insight\n",
    "# ----------------------------\n",
    "top_closed_trigrams = combined_counts.orderBy(F.col(\"log_odds_ratio\").desc())\n",
    "top_open_trigrams   = combined_counts.orderBy(F.col(\"log_odds_ratio\").asc())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "65fca69c-cc2e-4868-ab33-e09913a15417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top trigrams indicative of closed stores:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------+------------+----------+------------------+\n",
      "|ngram                           |closed_count|open_count|log_odds_ratio    |\n",
      "+--------------------------------+------------+----------+------------------+\n",
      "|scammers scammers scammers      |62          |0         |4.143134726391533 |\n",
      "|fluffy fluffy fluffy            |26          |0         |3.295836866004329 |\n",
      "|uuuuu uuuuu uuuuu               |16          |0         |2.833213344056216 |\n",
      "|spend courteous recommend       |5           |0         |1.791759469228055 |\n",
      "|professional decor try          |4           |0         |1.6094379124341003|\n",
      "|contact person forget           |4           |0         |1.6094379124341003|\n",
      "|issue fairly fooled             |4           |0         |1.6094379124341003|\n",
      "|mention recommend almost        |4           |0         |1.6094379124341003|\n",
      "|customers brought hous          |4           |0         |1.6094379124341003|\n",
      "|alcohol ordering issue          |4           |0         |1.6094379124341003|\n",
      "|generous alcohol ordering       |4           |0         |1.6094379124341003|\n",
      "|ordering issue fairly           |4           |0         |1.6094379124341003|\n",
      "|spoiling projection months      |4           |0         |1.6094379124341003|\n",
      "|unexpected professional decor   |4           |0         |1.6094379124341003|\n",
      "|pertama adalah facebook         |4           |0         |1.6094379124341003|\n",
      "|muncha muncha muncha            |4           |0         |1.6094379124341003|\n",
      "|careful robby manager           |4           |0         |1.6094379124341003|\n",
      "|dengan gambar pertama           |4           |0         |1.6094379124341003|\n",
      "|said cheating expensive         |4           |0         |1.6094379124341003|\n",
      "|either many types               |4           |0         |1.6094379124341003|\n",
      "|gambar pertama adalah           |4           |0         |1.6094379124341003|\n",
      "|adalah facebook sebelum         |4           |0         |1.6094379124341003|\n",
      "|cheating expensive without      |4           |0         |1.6094379124341003|\n",
      "|daal baati churma               |4           |0         |1.6094379124341003|\n",
      "|ketiga dengan gambar            |4           |0         |1.6094379124341003|\n",
      "|called said cheating            |4           |0         |1.6094379124341003|\n",
      "|brought hous specialities       |4           |0         |1.6094379124341003|\n",
      "|nymph cockroaches crawling      |4           |0         |1.6094379124341003|\n",
      "|anyone spend stated             |3           |0         |1.3862943611198906|\n",
      "|allow suppose charge            |3           |0         |1.3862943611198906|\n",
      "|okra weenis tingle              |3           |0         |1.3862943611198906|\n",
      "|beg someone bring               |3           |0         |1.3862943611198906|\n",
      "|indeed denied vianni            |3           |0         |1.3862943611198906|\n",
      "|broader least considering       |3           |0         |1.3862943611198906|\n",
      "|removed cost appreciated        |3           |0         |1.3862943611198906|\n",
      "|shows rude disrespectful        |3           |0         |1.3862943611198906|\n",
      "|wrong ask recommendations       |3           |0         |1.3862943611198906|\n",
      "|liver quite cordial             |3           |0         |1.3862943611198906|\n",
      "|exterior emanating smells       |3           |0         |1.3862943611198906|\n",
      "|wanting bathroom toilet         |3           |0         |1.3862943611198906|\n",
      "|overpriced felt ripped          |3           |0         |1.3862943611198906|\n",
      "|usually walked seated           |3           |0         |1.3862943611198906|\n",
      "|denied vianni stated            |3           |0         |1.3862943611198906|\n",
      "|honestly highly disappointed    |3           |0         |1.3862943611198906|\n",
      "|stated fabricated cameras       |3           |0         |1.3862943611198906|\n",
      "|attention constructed ingredient|3           |0         |1.3862943611198906|\n",
      "|stopped chatted definitely      |3           |0         |1.3862943611198906|\n",
      "|detect liver quite              |3           |0         |1.3862943611198906|\n",
      "|tough concierge easier          |3           |0         |1.3862943611198906|\n",
      "|typically includes otherwise    |3           |0         |1.3862943611198906|\n",
      "+--------------------------------+------------+----------+------------------+\n",
      "only showing top 50 rows\n",
      "\n",
      "Top trigrams indicative of open stores:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6902:================================================>     (40 + 5) / 45]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------+------------+----------+-------------------+\n",
      "|ngram                      |closed_count|open_count|log_odds_ratio     |\n",
      "+---------------------------+------------+----------+-------------------+\n",
      "|lolol lolol lolol          |0           |279       |-5.634789603169249 |\n",
      "|frickin frickin frickin    |0           |236       |-5.4680601411351315|\n",
      "|wearing masks gloves       |0           |201       |-5.308267697401205 |\n",
      "|worst customer wait        |0           |179       |-5.19295685089021  |\n",
      "|wait waited almost         |0           |155       |-5.049856007249537 |\n",
      "|took minutes cars          |1           |292       |-4.987025428457122 |\n",
      "|gave someone wait          |0           |145       |-4.983606621708336 |\n",
      "|stopping costs reasonable  |0           |142       |-4.962844630259907 |\n",
      "|ordered asked wait         |0           |140       |-4.948759890378168 |\n",
      "|loved members highly       |0           |137       |-4.927253685157205 |\n",
      "|forgot give asked          |0           |137       |-4.927253685157205 |\n",
      "|gave wrong gave            |1           |272       |-4.916324614625014 |\n",
      "|none wearing masks         |0           |135       |-4.912654885736052 |\n",
      "|feedback efficient whenever|0           |134       |-4.90527477843843  |\n",
      "|wearing mask properly      |0           |128       |-4.859812404361672 |\n",
      "|minutes cars ahead         |3           |493       |-4.816241156068032 |\n",
      "|covid safety measures      |0           |122       |-4.812184355372417 |\n",
      "|cashier rude asked         |0           |121       |-4.804021044733257 |\n",
      "|customers wearing masks    |0           |120       |-4.795790545596741 |\n",
      "|ordered paid received      |0           |119       |-4.787491742782046 |\n",
      "|paying attention customer  |0           |116       |-4.762173934797756 |\n",
      "|wearing masks properly     |0           |112       |-4.727387818712341 |\n",
      "|wait approximately minutes |0           |111       |-4.718498871295095 |\n",
      "|ordered given wrong        |0           |111       |-4.718498871295095 |\n",
      "|minute wait cars           |0           |109       |-4.700480365792417 |\n",
      "|cars waited minutes        |0           |109       |-4.700480365792417 |\n",
      "|cars took minutes          |1           |215       |-4.68213122712422  |\n",
      "|wait went waited           |0           |103       |-4.6443908991413725|\n",
      "|gave asked asked           |0           |102       |-4.634728988229636 |\n",
      "|wait seated definitely     |0           |102       |-4.634728988229636 |\n",
      "|wearing mask wearing       |0           |102       |-4.634728988229636 |\n",
      "|(translated google) loved  |0           |101       |-4.624972813284271 |\n",
      "|horrible customer wrong    |0           |101       |-4.624972813284271 |\n",
      "|forgot give gave           |0           |100       |-4.61512051684126  |\n",
      "|topmost doubt warmly       |0           |100       |-4.61512051684126  |\n",
      "|gave asked give            |0           |99        |-4.605170185988091 |\n",
      "|gets crowded wait          |2           |298       |-4.601831284722577 |\n",
      "|offers loved rates         |0           |98        |-4.59511985013459  |\n",
      "|orders missing items       |0           |97        |-4.584967478670572 |\n",
      "|needs observe customer     |0           |97        |-4.584967478670572 |\n",
      "|cleaning falta limpieza    |0           |97        |-4.584967478670572 |\n",
      "|ask put ask                |0           |96        |-4.574710978503383 |\n",
      "|ordered without put        |0           |95        |-4.564348191467836 |\n",
      "|sometimes forget give      |0           |95        |-4.564348191467836 |\n",
      "|wear masks gloves          |0           |95        |-4.564348191467836 |\n",
      "|forgot give went           |0           |94        |-4.553876891600541 |\n",
      "|boner boner boner          |0           |94        |-4.553876891600541 |\n",
      "|tuve esperar minutos       |0           |93        |-4.543294782270004 |\n",
      "|went many places           |0           |93        |-4.543294782270004 |\n",
      "|many homeless hanging      |1           |187       |-4.543294782270004 |\n",
      "+---------------------------+------------+----------+-------------------+\n",
      "only showing top 50 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# 8. Show results\n",
    "# ----------------------------\n",
    "print(\"Top trigrams indicative of closed stores:\")\n",
    "top_closed_trigrams.show(50, truncate=False)\n",
    "\n",
    "print(\"Top trigrams indicative of open stores:\")\n",
    "top_open_trigrams.show(50, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56610993-cbca-46cf-bf87-f278439b821f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "12c07c61-1aea-4e43-8857-8ba919355edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trigrams indicative of closed stores:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------+------------+----------+------------------+\n",
      "|ngram                          |closed_count|open_count|log_odds_ratio    |\n",
      "+-------------------------------+------------+----------+------------------+\n",
      "|scammers scammers scammers     |55          |0         |4.02535169073515  |\n",
      "|fluffy fluffy fluffy           |17          |0         |2.8903717578961645|\n",
      "|uuuuu uuuuu uuuuu              |16          |0         |2.833213344056216 |\n",
      "|spend courteous recommend      |5           |0         |1.791759469228055 |\n",
      "|gambar pertama adalah          |4           |0         |1.6094379124341003|\n",
      "|particular recommend arugula   |4           |0         |1.6094379124341003|\n",
      "|bathroom toilet prosper        |4           |0         |1.6094379124341003|\n",
      "|generous alcohol ordering      |4           |0         |1.6094379124341003|\n",
      "|recommend comparison many      |4           |0         |1.6094379124341003|\n",
      "|ordered takes prepare          |4           |0         |1.6094379124341003|\n",
      "|steal putting wallet           |4           |0         |1.6094379124341003|\n",
      "|ordering issue fairly          |4           |0         |1.6094379124341003|\n",
      "|said cheating expensive        |4           |0         |1.6094379124341003|\n",
      "|speaks generous alcohol        |4           |0         |1.6094379124341003|\n",
      "|waiter groupon coupon          |4           |0         |1.6094379124341003|\n",
      "|toilet prosper succeed         |4           |0         |1.6094379124341003|\n",
      "|called waitress went           |4           |0         |1.6094379124341003|\n",
      "|unexpected professional decor  |4           |0         |1.6094379124341003|\n",
      "|called said cheating           |4           |0         |1.6094379124341003|\n",
      "|nymph cockroaches crawling     |4           |0         |1.6094379124341003|\n",
      "|going steal putting            |4           |0         |1.6094379124341003|\n",
      "|tried months try               |4           |0         |1.6094379124341003|\n",
      "|subtleties noticed attention   |4           |0         |1.6094379124341003|\n",
      "|adalah facebook sebelum        |4           |0         |1.6094379124341003|\n",
      "|alcohol ordering issue         |4           |0         |1.6094379124341003|\n",
      "|ordered despite took           |4           |0         |1.6094379124341003|\n",
      "|dengan gambar pertama          |4           |0         |1.6094379124341003|\n",
      "|professional decor try         |4           |0         |1.6094379124341003|\n",
      "|clearly went wrong             |4           |0         |1.6094379124341003|\n",
      "|cheating expensive without     |4           |0         |1.6094379124341003|\n",
      "|attractive particular recommend|4           |0         |1.6094379124341003|\n",
      "|pertama adalah facebook        |4           |0         |1.6094379124341003|\n",
      "|ketiga dengan gambar           |4           |0         |1.6094379124341003|\n",
      "|changes personal lighting      |4           |0         |1.6094379124341003|\n",
      "|muncha muncha muncha           |4           |0         |1.6094379124341003|\n",
      "|mention recommend almost       |4           |0         |1.6094379124341003|\n",
      "|soupy mostly almost            |3           |0         |1.3862943611198906|\n",
      "|react said complete            |3           |0         |1.3862943611198906|\n",
      "|gave photos lying              |3           |0         |1.3862943611198906|\n",
      "|excited walked server          |3           |0         |1.3862943611198906|\n",
      "|broader least considering      |3           |0         |1.3862943611198906|\n",
      "|definitely tried groupon       |3           |0         |1.3862943611198906|\n",
      "|either many types              |3           |0         |1.3862943611198906|\n",
      "|piyo aish karo                 |3           |0         |1.3862943611198906|\n",
      "|exterior emanating smells      |3           |0         |1.3862943611198906|\n",
      "|shout customers find           |3           |0         |1.3862943611198906|\n",
      "|moderately accept appetizers   |3           |0         |1.3862943611198906|\n",
      "|significant majority vhs       |3           |0         |1.3862943611198906|\n",
      "|discovered layering filled     |3           |0         |1.3862943611198906|\n",
      "|expected wait looked           |3           |0         |1.3862943611198906|\n",
      "+-------------------------------+------------+----------+------------------+\n",
      "only showing top 50 rows\n",
      "\n",
      "Trigrams indicative of open stores:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6915:==============================================>       (39 + 6) / 45]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------+------------+----------+-------------------+\n",
      "|ngram                            |closed_count|open_count|log_odds_ratio     |\n",
      "+---------------------------------+------------+----------+-------------------+\n",
      "|lolol lolol lolol                |0           |363       |-5.8971538676367405|\n",
      "|frickin frickin frickin          |0           |220       |-5.3981627015177525|\n",
      "|wearing masks gloves             |0           |192       |-5.262690188904886 |\n",
      "|worst customer wait              |0           |177       |-5.181783550292085 |\n",
      "|wait waited almost               |0           |163       |-5.099866427824199 |\n",
      "|wrong missing items              |0           |160       |-5.081404364984463 |\n",
      "|took minutes cars                |1           |298       |-5.0072963928307415|\n",
      "|gave someone wait                |0           |148       |-5.003946305945459 |\n",
      "|covid highly recommend           |0           |139       |-4.941642422609305 |\n",
      "|rude customer skills             |0           |136       |-4.919980925828125 |\n",
      "|ordered asked wait               |0           |135       |-4.912654885736052 |\n",
      "|none wearing masks               |0           |131       |-4.882801922586371 |\n",
      "|loved members highly             |0           |129       |-4.867534450455582 |\n",
      "|feedback efficient whenever      |0           |129       |-4.867534450455582 |\n",
      "|cashier rude asked               |0           |127       |-4.852030263919617 |\n",
      "|following covid guidelines       |0           |125       |-4.836281906951478 |\n",
      "|someone taking orders            |0           |121       |-4.804021044733257 |\n",
      "|reviews excited try              |0           |120       |-4.795790545596741 |\n",
      "|covid safety measures            |0           |119       |-4.787491742782046 |\n",
      "|ordered paid received            |0           |118       |-4.77912349311153  |\n",
      "|customers wearing masks          |0           |118       |-4.77912349311153  |\n",
      "|typical highly recommend         |0           |117       |-4.770684624465665 |\n",
      "|wearing mask properly            |0           |116       |-4.762173934797756 |\n",
      "|minutes cars ahead               |3           |460       |-4.747103681876758 |\n",
      "|paying attention customer        |0           |112       |-4.727387818712341 |\n",
      "|customer rates convenient        |0           |112       |-4.727387818712341 |\n",
      "|cars waited minutes              |0           |110       |-4.709530201312334 |\n",
      "|wait approximately minutes       |0           |109       |-4.700480365792417 |\n",
      "|wearing masks properly           |0           |108       |-4.6913478822291435|\n",
      "|forgot give gave                 |0           |105       |-4.663439094112067 |\n",
      "|wrong ordered gave               |0           |104       |-4.653960350157523 |\n",
      "|wait seated definitely           |0           |104       |-4.653960350157523 |\n",
      "|topmost doubt warmly             |0           |103       |-4.6443908991413725|\n",
      "|ordered given wrong              |0           |102       |-4.634728988229636 |\n",
      "|orders missing items             |0           |101       |-4.624972813284271 |\n",
      "|wait went waited                 |0           |100       |-4.61512051684126  |\n",
      "|wearing mask wearing             |0           |100       |-4.61512051684126  |\n",
      "|wait try wait                    |0           |100       |-4.61512051684126  |\n",
      "|favourite places arrived         |0           |99        |-4.605170185988091 |\n",
      "|minute wait cars                 |0           |98        |-4.59511985013459  |\n",
      "|sometimes forget give            |0           |98        |-4.59511985013459  |\n",
      "|offers loved rates               |0           |97        |-4.584967478670572 |\n",
      "|manager horrible customer        |0           |95        |-4.564348191467836 |\n",
      "|boner boner boner                |0           |94        |-4.553876891600541 |\n",
      "|surely recommend customer        |0           |94        |-4.553876891600541 |\n",
      "|gave asked asked                 |0           |94        |-4.553876891600541 |\n",
      "|many homeless hanging            |1           |186       |-4.537961436294641 |\n",
      "|customer mal cliente             |0           |92        |-4.532599493153256 |\n",
      "|definitely wait definitely       |0           |92        |-4.532599493153256 |\n",
      "|conveniently regularly delightful|0           |91        |-4.5217885770490405|\n",
      "+---------------------------------+------------+----------+-------------------+\n",
      "only showing top 50 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import ArrayType, StringType\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, NGram\n",
    "\n",
    "# ----------------------------\n",
    "# 1. Filter closed and open store reviews\n",
    "# ----------------------------\n",
    "closed_df = combined_df.filter(\n",
    "    (F.col(\"text\").isNotNull()) &\n",
    "    (F.col(\"rating\").isNotNull()) &\n",
    "    (F.col(\"permanent_closed\") == 1)\n",
    ")\n",
    "\n",
    "open_df = combined_df.filter(\n",
    "    (F.col(\"text\").isNotNull()) &\n",
    "    (F.col(\"rating\").isNotNull()) &\n",
    "    (F.col(\"permanent_closed\") == 0)\n",
    ")\n",
    "\n",
    "# Optional: sample 1% for testing\n",
    "closed_df = closed_df.sample(1.0, seed=42)\n",
    "open_df   = open_df.sample(1.0, seed=42)\n",
    "\n",
    "# ----------------------------\n",
    "# 2. Tokenize & clean\n",
    "# ----------------------------\n",
    "def clean_tokens(df):\n",
    "    tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"tokens\")\n",
    "    df = tokenizer.transform(df)\n",
    "\n",
    "    stop_remover = StopWordsRemover(inputCol=\"tokens\", outputCol=\"tokens_clean\")\n",
    "    df = stop_remover.transform(df)\n",
    "\n",
    "    # Keep only alphabetic tokens of length >=3\n",
    "    df = df.withColumn(\n",
    "        \"english_tokens\",\n",
    "        F.expr(\"filter(transform(tokens_clean, x -> lower(x)), x -> x rlike '^[a-z]{3,}$')\")\n",
    "    )\n",
    "\n",
    "    # Filter out nonsense tokens like repeated letters\n",
    "    df = df.withColumn(\n",
    "        \"english_tokens\",\n",
    "        F.expr(\"filter(english_tokens, x -> not x rlike '^(.)\\\\1+$')\")  # removes 'aaaa' or 'uuu'\n",
    "    )\n",
    "\n",
    "    return df\n",
    "\n",
    "closed_df = clean_tokens(closed_df)\n",
    "open_df   = clean_tokens(open_df)\n",
    "\n",
    "# ----------------------------\n",
    "# 3. Remove store name words\n",
    "# ----------------------------\n",
    "store_words_list = (\n",
    "    combined_df\n",
    "    .select(F.lower(F.col(\"store_name\")).alias(\"name\"))\n",
    "    .select(F.split(\"name\", \" \").alias(\"words\"))\n",
    "    .select(F.explode(\"words\").alias(\"w\"))\n",
    "    .filter(F.length(\"w\") > 2)\n",
    "    .distinct()\n",
    "    .rdd.flatMap(lambda x: x)\n",
    "    .collect()\n",
    ")\n",
    "broadcast_store_words = spark.sparkContext.broadcast(set(store_words_list))\n",
    "\n",
    "def remove_store_words(tokens):\n",
    "    return [t for t in tokens if t not in broadcast_store_words.value]\n",
    "\n",
    "remove_store_words_udf = F.udf(remove_store_words, ArrayType(StringType()))\n",
    "\n",
    "closed_df = closed_df.withColumn(\"operational_tokens\", remove_store_words_udf(\"english_tokens\"))\n",
    "open_df   = open_df.withColumn(\"operational_tokens\", remove_store_words_udf(\"english_tokens\"))\n",
    "\n",
    "# ----------------------------\n",
    "# 4. Create trigrams\n",
    "# ----------------------------\n",
    "trigrammer = NGram(n=3, inputCol=\"operational_tokens\", outputCol=\"trigrams\")\n",
    "closed_df = trigrammer.transform(closed_df)\n",
    "open_df   = trigrammer.transform(open_df)\n",
    "\n",
    "# ----------------------------\n",
    "# 5. Explode trigrams and count\n",
    "# ----------------------------\n",
    "def trigram_count(df, count_col):\n",
    "    exploded = df.select(F.explode(\"trigrams\").alias(\"ngram\"))\n",
    "    return exploded.groupBy(\"ngram\").count().withColumnRenamed(\"count\", count_col)\n",
    "\n",
    "closed_counts = trigram_count(closed_df, \"closed_count\")\n",
    "open_counts   = trigram_count(open_df, \"open_count\")\n",
    "\n",
    "# ----------------------------\n",
    "# 6. Combine counts & compute log-odds\n",
    "# ----------------------------\n",
    "combined_counts = closed_counts.join(open_counts, on=\"ngram\", how=\"outer\").fillna(0)\n",
    "combined_counts = combined_counts.withColumn(\n",
    "    \"log_odds_ratio\",\n",
    "    F.log((F.col(\"closed_count\")+1)/(F.col(\"open_count\")+1))\n",
    ")\n",
    "\n",
    "# ----------------------------\n",
    "# 7. Rank for comparative insight\n",
    "# ----------------------------\n",
    "top_closed_trigrams = combined_counts.orderBy(F.col(\"log_odds_ratio\").desc())\n",
    "top_open_trigrams   = combined_counts.orderBy(F.col(\"log_odds_ratio\").asc())\n",
    "\n",
    "# ----------------------------\n",
    "# 8. Show top results\n",
    "# ----------------------------\n",
    "print(\"Trigrams indicative of closed stores:\")\n",
    "top_closed_trigrams.show(50, truncate=False)\n",
    "\n",
    "print(\"Trigrams indicative of open stores:\")\n",
    "top_open_trigrams.show(50, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8ec30d78-e830-49b2-ba20-6e7e0cec7fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4-grams indicative of closed stores:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------+------------+----------+------------------+\n",
      "|ngram                                    |closed_count|open_count|log_odds_ratio    |\n",
      "+-----------------------------------------+------------+----------+------------------+\n",
      "|scammers scammers scammers scammers      |61          |0         |4.127134385045092 |\n",
      "|fluffy fluffy fluffy fluffy              |16          |0         |2.833213344056216 |\n",
      "|uuuuu uuuuu uuuuu uuuuu                  |9           |0         |2.302585092994046 |\n",
      "|gambar pertama adalah facebook           |4           |0         |1.6094379124341003|\n",
      "|dengan gambar pertama adalah             |4           |0         |1.6094379124341003|\n",
      "|called said cheating expensive           |4           |0         |1.6094379124341003|\n",
      "|alcohol ordering issue fairly            |4           |0         |1.6094379124341003|\n",
      "|said cheating expensive without          |4           |0         |1.6094379124341003|\n",
      "|ketiga dengan gambar pertama             |4           |0         |1.6094379124341003|\n",
      "|generous alcohol ordering issue          |4           |0         |1.6094379124341003|\n",
      "|pertama adalah facebook sebelum          |4           |0         |1.6094379124341003|\n",
      "|give threatened numerous invited         |3           |0         |1.3862943611198906|\n",
      "|ticked asked bartender transfer          |3           |0         |1.3862943611198906|\n",
      "|outstanding subtleties noticed attention |3           |0         |1.3862943611198906|\n",
      "|credit along debit without               |3           |0         |1.3862943611198906|\n",
      "|asco disaster trays experiences          |3           |0         |1.3862943611198906|\n",
      "|enter completely forget carefully        |3           |0         |1.3862943611198906|\n",
      "|definitely type multiple interior        |3           |0         |1.3862943611198906|\n",
      "|quite certainly actually afterthought    |3           |0         |1.3862943611198906|\n",
      "|careful robby manager sick               |3           |0         |1.3862943611198906|\n",
      "|majority vhs tapes films                 |3           |0         |1.3862943611198906|\n",
      "|indeed denied vianni stated              |3           |0         |1.3862943611198906|\n",
      "|bathroom toilet prosper succeed          |3           |0         |1.3862943611198906|\n",
      "|recommendation opens already updated     |3           |0         |1.3862943611198906|\n",
      "|bring suggest trying brownie             |3           |0         |1.3862943611198906|\n",
      "|answer definitely places accessible      |3           |0         |1.3862943611198906|\n",
      "|respectful lack hygiene premises         |3           |0         |1.3862943611198906|\n",
      "|perhaps grows older kicks                |3           |0         |1.3862943611198906|\n",
      "|unexpected professional decor try        |3           |0         |1.3862943611198906|\n",
      "|spend stated uber instead                |3           |0         |1.3862943611198906|\n",
      "|week surprised find birthday             |3           |0         |1.3862943611198906|\n",
      "|wait minutes especially considering      |3           |0         |1.3862943611198906|\n",
      "|surprised find birthday seated           |3           |0         |1.3862943611198906|\n",
      "|waiter give password avoid               |3           |0         |1.3862943611198906|\n",
      "|speaks generous alcohol ordering         |3           |0         |1.3862943611198906|\n",
      "|manager lyn expressed concern            |3           |0         |1.3862943611198906|\n",
      "|went discovered chis previous            |3           |0         |1.3862943611198906|\n",
      "|waiter ignored questions though          |3           |0         |1.3862943611198906|\n",
      "|ignored questions though asked           |3           |0         |1.3862943611198906|\n",
      "|applauded sampler scallop presentation   |3           |0         |1.3862943611198906|\n",
      "|ordered week worse verbally              |3           |0         |1.3862943611198906|\n",
      "|manager engage fighting speaking         |3           |0         |1.3862943611198906|\n",
      "|cancelled thats review helps             |3           |0         |1.3862943611198906|\n",
      "|professional specially helpful especially|3           |0         |1.3862943611198906|\n",
      "|recently recommendations rundown exterior|3           |0         |1.3862943611198906|\n",
      "|find birthday seated ordered             |3           |0         |1.3862943611198906|\n",
      "|recently quite certainly actually        |3           |0         |1.3862943611198906|\n",
      "|detect liver quite cordial               |3           |0         |1.3862943611198906|\n",
      "|week decided leave manager               |3           |0         |1.3862943611198906|\n",
      "|mushrooms sense amount put               |3           |0         |1.3862943611198906|\n",
      "+-----------------------------------------+------------+----------+------------------+\n",
      "only showing top 50 rows\n",
      "\n",
      "4-grams indicative of open stores:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6925:=============================================>        (39 + 7) / 46]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------+------------+----------+-------------------+\n",
      "|ngram                                    |closed_count|open_count|log_odds_ratio     |\n",
      "+-----------------------------------------+------------+----------+-------------------+\n",
      "|lolol lolol lolol lolol                  |0           |262       |-5.572154032177765 |\n",
      "|frickin frickin frickin frickin          |0           |176       |-5.176149732573829 |\n",
      "|regularly charge convenient rates        |0           |117       |-4.770684624465665 |\n",
      "|comes instantly many types               |0           |95        |-4.564348191467836 |\n",
      "|boner boner boner boner                  |0           |93        |-4.543294782270004 |\n",
      "|trying consistently towards visitors     |1           |182       |-4.516338972281476 |\n",
      "|constantly charge reasonable rates       |0           |90        |-4.51085950651685  |\n",
      "|cars ahead took minutes                  |0           |90        |-4.51085950651685  |\n",
      "|surely recommend visiting customer       |0           |87        |-4.477336814478207 |\n",
      "|comes straightaway many types            |0           |86        |-4.465908118654584 |\n",
      "|seems needs observe customer             |0           |84        |-4.442651256490317 |\n",
      "|pacer meme deadthe pacer                 |0           |81        |-4.406719247264253 |\n",
      "|meme deadthe pacer meme                  |0           |80        |-4.394449154672439 |\n",
      "|rates efficient definitely recommend     |0           |79        |-4.382026634673881 |\n",
      "|deadthe pacer meme deadthe               |0           |79        |-4.382026634673881 |\n",
      "|waited minutes went ask                  |0           |77        |-4.356708826689592 |\n",
      "|members welcomed felt loved              |0           |75        |-4.330733340286331 |\n",
      "|suggests everytime comes straightaway    |0           |74        |-4.31748811353631  |\n",
      "|towards clients frequently highly        |0           |71        |-4.276666119016055 |\n",
      "|prefere opportunity whenever need        |0           |71        |-4.276666119016055 |\n",
      "|productive personal definitely recommend |0           |70        |-4.2626798770413155|\n",
      "|highest feedback efficient whenever      |0           |68        |-4.23410650459726  |\n",
      "|took minutes cars ahead                  |0           |68        |-4.23410650459726  |\n",
      "|portions affordable regularly organized  |0           |67        |-4.219507705176107 |\n",
      "|reasonable considerable portions members |0           |66        |-4.204692619390966 |\n",
      "|(translated google)  y                   |0           |66        |-4.204692619390966 |\n",
      "|called asked manager said                |0           |65        |-4.189654742026425 |\n",
      "|put shall surely highly                  |1           |128       |-4.1666652238017265|\n",
      "|everytime need decent comes              |0           |63        |-4.1588830833596715|\n",
      "|giving portions affordable consistently  |0           |61        |-4.127134385045092 |\n",
      "|highest recommendation generous whenever |0           |61        |-4.127134385045092 |\n",
      "|provide consistently towards customers   |0           |59        |-4.0943445622221   |\n",
      "|suggests whenever decent comes           |0           |59        |-4.0943445622221   |\n",
      "|portions affordable liked members        |0           |59        |-4.0943445622221   |\n",
      "|rates effective amiable highly           |0           |59        |-4.0943445622221   |\n",
      "|waited minutes cars ahead                |1           |117       |-4.07753744390572  |\n",
      "|highly recommend definitely returning    |0           |58        |-4.07753744390572  |\n",
      "|productive amiable highly recommend      |0           |57        |-4.060443010546419 |\n",
      "|warmest feedback efficient whenever      |0           |57        |-4.060443010546419 |\n",
      "|generous portions economical enjoyed     |0           |56        |-4.04305126783455  |\n",
      "|put shall doubt highly                   |1           |112       |-4.034240638152395 |\n",
      "|definitely recommend reasonable generous |0           |55        |-4.02535169073515  |\n",
      "|members content decided try              |0           |54        |-4.007333185232471 |\n",
      "|enjoyed highly recommend anyone          |0           |54        |-4.007333185232471 |\n",
      "|(translated google)  excelente           |1           |109       |-4.007333185232471 |\n",
      "|give consistently towards customers      |0           |54        |-4.007333185232471 |\n",
      "|productive attentive definitely recommend|0           |53        |-3.9889840465642745|\n",
      "|highly recommend recomiendo ampliamente  |0           |53        |-3.9889840465642745|\n",
      "|generous portions reasonable loved       |0           |53        |-3.9889840465642745|\n",
      "|arrived rapidly definitely recommend     |0           |53        |-3.9889840465642745|\n",
      "+-----------------------------------------+------------+----------+-------------------+\n",
      "only showing top 50 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# 4. Create 4-grams\n",
    "# ----------------------------\n",
    "four_grammer = NGram(n=4, inputCol=\"operational_tokens\", outputCol=\"four_grams\")\n",
    "closed_df = four_grammer.transform(closed_df)\n",
    "open_df   = four_grammer.transform(open_df)\n",
    "\n",
    "# ----------------------------\n",
    "# 5. Explode 4-grams and count\n",
    "# ----------------------------\n",
    "def four_gram_count(df, count_col):\n",
    "    return df.select(F.explode(\"four_grams\").alias(\"ngram\")) \\\n",
    "             .groupBy(\"ngram\").count().withColumnRenamed(\"count\", count_col)\n",
    "\n",
    "closed_counts = four_gram_count(closed_df, \"closed_count\")\n",
    "open_counts   = four_gram_count(open_df, \"open_count\")\n",
    "\n",
    "# ----------------------------\n",
    "# 6. Combine counts and compute log-odds\n",
    "# ----------------------------\n",
    "combined_counts = closed_counts.join(open_counts, on=\"ngram\", how=\"outer\").fillna(0)\n",
    "combined_counts = combined_counts.withColumn(\n",
    "    \"log_odds_ratio\",\n",
    "    F.log((F.col(\"closed_count\")+1) / (F.col(\"open_count\")+1))\n",
    ")\n",
    "\n",
    "# ----------------------------\n",
    "# 7. Rank for comparative insight\n",
    "# ----------------------------\n",
    "top_closed_4_grams = combined_counts.orderBy(F.col(\"log_odds_ratio\").desc())\n",
    "top_open_4_grams   = combined_counts.orderBy(F.col(\"log_odds_ratio\").asc())\n",
    "\n",
    "# ----------------------------\n",
    "# 8. Show top results\n",
    "# ----------------------------\n",
    "print(\"4-grams indicative of closed stores:\")\n",
    "top_closed_4_grams.show(50, truncate=False)\n",
    "\n",
    "print(\"4-grams indicative of open stores:\")\n",
    "top_open_4_grams.show(50, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8b56b29d-996f-4ad5-97aa-9a566f8372cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trigrams indicative of closed stores:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+------------+----------+------------------+\n",
      "|ngram                         |closed_count|open_count|log_odds_ratio    |\n",
      "+------------------------------+------------+----------+------------------+\n",
      "|scammers scammers scammers    |61          |0         |4.127134385045092 |\n",
      "|fluffy fluffy fluffy          |17          |0         |2.8903717578961645|\n",
      "|uuuuu uuuuu uuuuu             |10          |0         |2.3978952727983707|\n",
      "|spend courteous recommend     |5           |0         |1.791759469228055 |\n",
      "|professional decor try        |4           |0         |1.6094379124341003|\n",
      "|items waited patiently        |4           |0         |1.6094379124341003|\n",
      "|including sparkling multitudes|4           |0         |1.6094379124341003|\n",
      "|unexpected professional decor |4           |0         |1.6094379124341003|\n",
      "|issue fairly fooled           |4           |0         |1.6094379124341003|\n",
      "|ordering issue fairly         |4           |0         |1.6094379124341003|\n",
      "|cheater advised wait          |4           |0         |1.6094379124341003|\n",
      "|withdrawn refused showed      |4           |0         |1.6094379124341003|\n",
      "|muncha muncha muncha          |4           |0         |1.6094379124341003|\n",
      "|pertama adalah facebook       |4           |0         |1.6094379124341003|\n",
      "|called said cheating          |4           |0         |1.6094379124341003|\n",
      "|either many types             |4           |0         |1.6094379124341003|\n",
      "|gambar pertama adalah         |4           |0         |1.6094379124341003|\n",
      "|generous alcohol ordering     |4           |0         |1.6094379124341003|\n",
      "|brought hous specialities     |4           |0         |1.6094379124341003|\n",
      "|said cheating expensive       |4           |0         |1.6094379124341003|\n",
      "|speaks generous alcohol       |4           |0         |1.6094379124341003|\n",
      "|alcohol ordering issue        |4           |0         |1.6094379124341003|\n",
      "|adalah facebook sebelum       |4           |0         |1.6094379124341003|\n",
      "|nicely responsibly sourced    |4           |0         |1.6094379124341003|\n",
      "|tried months try              |4           |0         |1.6094379124341003|\n",
      "|daal baati churma             |4           |0         |1.6094379124341003|\n",
      "|ketiga dengan gambar          |4           |0         |1.6094379124341003|\n",
      "|dengan gambar pertama         |4           |0         |1.6094379124341003|\n",
      "|cheating expensive without    |4           |0         |1.6094379124341003|\n",
      "|manager said inspection       |3           |0         |1.3862943611198906|\n",
      "|afterthought drinker chosen   |3           |0         |1.3862943611198906|\n",
      "|majority vhs tapes            |3           |0         |1.3862943611198906|\n",
      "|ask give mechanic             |3           |0         |1.3862943611198906|\n",
      "|credit informed refund        |3           |0         |1.3862943611198906|\n",
      "|lyn expressed concern         |3           |0         |1.3862943611198906|\n",
      "|applauded sampler scallop     |3           |0         |1.3862943611198906|\n",
      "|definitely helpful although   |3           |0         |1.3862943611198906|\n",
      "|disappointed going along      |3           |0         |1.3862943611198906|\n",
      "|week decided indeed           |3           |0         |1.3862943611198906|\n",
      "|going steal putting           |3           |0         |1.3862943611198906|\n",
      "|sugary detect liver           |3           |0         |1.3862943611198906|\n",
      "|deleted write ordered         |3           |0         |1.3862943611198906|\n",
      "|teryaki teryaki teryaki       |3           |0         |1.3862943611198906|\n",
      "|many balls diluted            |3           |0         |1.3862943611198906|\n",
      "|taking brownie avoid          |3           |0         |1.3862943611198906|\n",
      "|terrible overpriced given     |3           |0         |1.3862943611198906|\n",
      "|year makes horrible           |3           |0         |1.3862943611198906|\n",
      "|entering shorts welcomed      |3           |0         |1.3862943611198906|\n",
      "|approached taking said        |3           |0         |1.3862943611198906|\n",
      "|presentation twists affordable|3           |0         |1.3862943611198906|\n",
      "+------------------------------+------------+----------+------------------+\n",
      "only showing top 50 rows\n",
      "\n",
      "Trigrams indicative of open stores:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6938:==============================================>       (39 + 6) / 45]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------+------------+----------+-------------------+\n",
      "|ngram                            |closed_count|open_count|log_odds_ratio     |\n",
      "+---------------------------------+------------+----------+-------------------+\n",
      "|lolol lolol lolol                |0           |312       |-5.746203190540153 |\n",
      "|frickin frickin frickin          |0           |305       |-5.723585101952381 |\n",
      "|wearing masks gloves             |0           |192       |-5.262690188904886 |\n",
      "|worst customer wait              |0           |159       |-5.075173815233827 |\n",
      "|wait waited almost               |0           |154       |-5.043425116919247 |\n",
      "|waited minutes cars              |2           |462       |-5.039114765418124 |\n",
      "|took minutes cars                |1           |300       |-5.01396308418893  |\n",
      "|ordered asked wait               |0           |144       |-4.976733742420574 |\n",
      "|gave someone wait                |0           |144       |-4.976733742420574 |\n",
      "|gave wrong gave                  |1           |267       |-4.897839799950911 |\n",
      "|wearing mask properly            |0           |127       |-4.852030263919617 |\n",
      "|feedback efficient whenever      |0           |126       |-4.844187086458591 |\n",
      "|minutes cars ahead               |3           |504       |-4.838264068155469 |\n",
      "|cashier rude asked               |0           |123       |-4.820281565605037 |\n",
      "|none wearing masks               |0           |123       |-4.820281565605037 |\n",
      "|loved members highly             |0           |121       |-4.804021044733257 |\n",
      "|wearing masks properly           |0           |120       |-4.795790545596741 |\n",
      "|cars waited minutes              |0           |118       |-4.77912349311153  |\n",
      "|customers wearing masks          |0           |118       |-4.77912349311153  |\n",
      "|ordered paid received            |0           |116       |-4.762173934797756 |\n",
      "|took minutes horrible            |0           |115       |-4.7535901911063645|\n",
      "|paying attention customer        |0           |114       |-4.74493212836325  |\n",
      "|wait approximately minutes       |0           |113       |-4.736198448394496 |\n",
      "|provide portions inexpensive     |0           |112       |-4.727387818712341 |\n",
      "|waiters give agreeable           |0           |111       |-4.718498871295095 |\n",
      "|covid safety measures            |0           |108       |-4.6913478822291435|\n",
      "|boner boner boner                |0           |107       |-4.68213122712422  |\n",
      "|forgot give gave                 |0           |107       |-4.68213122712422  |\n",
      "|topmost doubt warmly             |0           |106       |-4.672828834461907 |\n",
      "|wearing mask wearing             |0           |106       |-4.672828834461907 |\n",
      "|wait went waited                 |0           |105       |-4.663439094112067 |\n",
      "|minute wait cars                 |0           |105       |-4.663439094112067 |\n",
      "|offers loved rates               |0           |103       |-4.6443908991413725|\n",
      "|ordered given wrong              |0           |102       |-4.634728988229636 |\n",
      "|gave asked asked                 |0           |101       |-4.624972813284271 |\n",
      "|wait seated definitely           |0           |101       |-4.624972813284271 |\n",
      "|comes instantly many             |0           |101       |-4.624972813284271 |\n",
      "|messed gave instead              |0           |101       |-4.624972813284271 |\n",
      "|tuve esperar minutos             |0           |99        |-4.605170185988091 |\n",
      "|wait try wait                    |0           |98        |-4.59511985013459  |\n",
      "|orders missing items             |0           |98        |-4.59511985013459  |\n",
      "|instantly many types             |0           |98        |-4.59511985013459  |\n",
      "|many homeless hanging            |1           |195       |-4.584967478670572 |\n",
      "|gave asked give                  |0           |97        |-4.584967478670572 |\n",
      "|portions recommend anyone        |0           |96        |-4.574710978503383 |\n",
      "|forgot give went                 |0           |95        |-4.564348191467836 |\n",
      "|manager duty rude                |0           |95        |-4.564348191467836 |\n",
      "|conveniently regularly delightful|0           |95        |-4.564348191467836 |\n",
      "|customer mal cliente             |0           |95        |-4.564348191467836 |\n",
      "|ordered went gave                |0           |94        |-4.553876891600541 |\n",
      "+---------------------------------+------------+----------+-------------------+\n",
      "only showing top 50 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import ArrayType, StringType\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, NGram\n",
    "\n",
    "# ----------------------------\n",
    "# 1. Filter closed and open store reviews\n",
    "# ----------------------------\n",
    "closed_df = combined_df.filter(\n",
    "    (F.col(\"text\").isNotNull()) &\n",
    "    (F.col(\"rating\").isNotNull()) &\n",
    "    (F.col(\"permanent_closed\") == 1)\n",
    ")\n",
    "\n",
    "open_df = combined_df.filter(\n",
    "    (F.col(\"text\").isNotNull()) &\n",
    "    (F.col(\"rating\").isNotNull()) &\n",
    "    (F.col(\"permanent_closed\") == 0)\n",
    ")\n",
    "\n",
    "# Optional: sample small fraction for testing\n",
    "closed_df = closed_df.sample(fraction=1.0, seed=42)\n",
    "open_df   = open_df.sample(fraction=1.0, seed=42)\n",
    "\n",
    "# ----------------------------\n",
    "# 2. Tokenize and clean\n",
    "# ----------------------------\n",
    "def clean_tokens(df):\n",
    "    tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"tokens\")\n",
    "    df = tokenizer.transform(df)\n",
    "\n",
    "    stop_remover = StopWordsRemover(inputCol=\"tokens\", outputCol=\"tokens_clean\")\n",
    "    df = stop_remover.transform(df)\n",
    "\n",
    "    # Keep only alphabetic tokens of length >= 3\n",
    "    df = df.withColumn(\n",
    "        \"english_tokens\",\n",
    "        F.expr(\"filter(transform(tokens_clean, x -> lower(x)), x -> x rlike '^[a-z]{3,}$')\")\n",
    "    )\n",
    "\n",
    "    # Remove repeated-letter nonsense tokens like 'aaaa' or 'uuu'\n",
    "    df = df.withColumn(\n",
    "        \"english_tokens\",\n",
    "        F.expr(\"filter(english_tokens, x -> not x rlike '^(.)\\\\1+$')\")\n",
    "    )\n",
    "    return df\n",
    "\n",
    "closed_df = clean_tokens(closed_df)\n",
    "open_df   = clean_tokens(open_df)\n",
    "\n",
    "# ----------------------------\n",
    "# 3. Remove store name words using a UDF (safe for special characters)\n",
    "# ----------------------------\n",
    "store_words_list = (\n",
    "    combined_df\n",
    "    .select(F.lower(F.col(\"store_name\")).alias(\"name\"))\n",
    "    .select(F.split(\"name\", \" \").alias(\"words\"))\n",
    "    .select(F.explode(\"words\").alias(\"w\"))\n",
    "    .filter(F.length(\"w\") > 2)\n",
    "    .distinct()\n",
    "    .rdd.flatMap(lambda x: x)\n",
    "    .collect()\n",
    ")\n",
    "broadcast_store_words = spark.sparkContext.broadcast(set(store_words_list))\n",
    "\n",
    "def remove_store_words(tokens):\n",
    "    if tokens is None:\n",
    "        return []\n",
    "    return [t for t in tokens if t not in broadcast_store_words.value]\n",
    "\n",
    "remove_store_words_udf = F.udf(remove_store_words, ArrayType(StringType()))\n",
    "\n",
    "closed_df = closed_df.withColumn(\"operational_tokens\", remove_store_words_udf(\"english_tokens\"))\n",
    "open_df   = open_df.withColumn(\"operational_tokens\", remove_store_words_udf(\"english_tokens\"))\n",
    "\n",
    "# ----------------------------\n",
    "# 4. Create trigrams\n",
    "# ----------------------------\n",
    "trigrammer = NGram(n=3, inputCol=\"operational_tokens\", outputCol=\"trigrams\")\n",
    "closed_df = trigrammer.transform(closed_df)\n",
    "open_df   = trigrammer.transform(open_df)\n",
    "\n",
    "# ----------------------------\n",
    "# 5. Explode trigrams and count\n",
    "# ----------------------------\n",
    "def trigram_count(df, count_col):\n",
    "    return df.select(F.explode(\"trigrams\").alias(\"ngram\")) \\\n",
    "             .groupBy(\"ngram\").count().withColumnRenamed(\"count\", count_col)\n",
    "\n",
    "closed_counts = trigram_count(closed_df, \"closed_count\")\n",
    "open_counts   = trigram_count(open_df, \"open_count\")\n",
    "\n",
    "# ----------------------------\n",
    "# 6. Combine counts and compute log-odds\n",
    "# ----------------------------\n",
    "combined_counts = closed_counts.join(open_counts, on=\"ngram\", how=\"outer\").fillna(0)\n",
    "combined_counts = combined_counts.withColumn(\n",
    "    \"log_odds_ratio\",\n",
    "    F.log((F.col(\"closed_count\")+1) / (F.col(\"open_count\")+1))\n",
    ")\n",
    "\n",
    "# ----------------------------\n",
    "# 7. Rank for comparative insight\n",
    "# ----------------------------\n",
    "top_closed_trigrams = combined_counts.orderBy(F.col(\"log_odds_ratio\").desc())\n",
    "top_open_trigrams   = combined_counts.orderBy(F.col(\"log_odds_ratio\").asc())\n",
    "\n",
    "# ----------------------------\n",
    "# 8. Show top results\n",
    "# ----------------------------\n",
    "print(\"Trigrams indicative of closed stores:\")\n",
    "top_closed_trigrams.show(50, truncate=False)\n",
    "\n",
    "print(\"Trigrams indicative of open stores:\")\n",
    "top_open_trigrams.show(50, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f9b93f82-f7c7-465a-856c-08d83c3729b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-grams indicative of closed stores:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------+------------+----------+------------------+\n",
      "|ngram                                             |closed_count|open_count|log_odds_ratio    |\n",
      "+--------------------------------------------------+------------+----------+------------------+\n",
      "|scammers scammers scammers scammers scammers      |53          |0         |3.9889840465642745|\n",
      "|fluffy fluffy fluffy fluffy fluffy                |15          |0         |2.772588722239781 |\n",
      "|informed refund almost year passed                |4           |0         |1.6094379124341003|\n",
      "|contacted credit informed refund almost           |4           |0         |1.6094379124341003|\n",
      "|refund almost year passed received                |4           |0         |1.6094379124341003|\n",
      "|gambar pertama adalah facebook sebelum            |4           |0         |1.6094379124341003|\n",
      "|called said cheating expensive without            |4           |0         |1.6094379124341003|\n",
      "|ketiga dengan gambar pertama adalah               |4           |0         |1.6094379124341003|\n",
      "|credit informed refund almost year                |4           |0         |1.6094379124341003|\n",
      "|dengan gambar pertama adalah facebook             |4           |0         |1.6094379124341003|\n",
      "|voucher happened approximately careful cashier    |3           |0         |1.3862943611198906|\n",
      "|calls shout customers find personally             |3           |0         |1.3862943611198906|\n",
      "|indeed denied vianni stated fabricated            |3           |0         |1.3862943611198906|\n",
      "|attractive particular recommend arugula dressing  |3           |0         |1.3862943611198906|\n",
      "|week worse verbally assaulted upset               |3           |0         |1.3862943611198906|\n",
      "|tried many honestly heard adding                  |3           |0         |1.3862943611198906|\n",
      "|spend stated uber instead cancelled               |3           |0         |1.3862943611198906|\n",
      "|audio driver recommend anyone spend               |3           |0         |1.3862943611198906|\n",
      "|already mentioned ordeal trying asked             |3           |0         |1.3862943611198906|\n",
      "|traveling eau accidentally seemed entering        |3           |0         |1.3862943611198906|\n",
      "|speaking manager lyn expressed concern            |3           |0         |1.3862943611198906|\n",
      "|recommendations rundown exterior emanating smells |3           |0         |1.3862943611198906|\n",
      "|took credit along debit without                   |3           |0         |1.3862943611198906|\n",
      "|greeted visiting said glad ordered                |3           |0         |1.3862943611198906|\n",
      "|exterior emanating smells including sparkling     |3           |0         |1.3862943611198906|\n",
      "|stopped week surprised find birthday              |3           |0         |1.3862943611198906|\n",
      "|cashier going steal putting wallet                |3           |0         |1.3862943611198906|\n",
      "|constructed ingredient chilled warmer forkful     |3           |0         |1.3862943611198906|\n",
      "|denied vianni stated fabricated cameras           |3           |0         |1.3862943611198906|\n",
      "|concern said follow week decided                  |3           |0         |1.3862943611198906|\n",
      "|bring suggest trying brownie gorgeous             |3           |0         |1.3862943611198906|\n",
      "|stuck previous customers asco disaster            |3           |0         |1.3862943611198906|\n",
      "|generous alcohol ordering issue fairly            |3           |0         |1.3862943611198906|\n",
      "|noisy wait either incredibly charming             |3           |0         |1.3862943611198906|\n",
      "|drinker chosen typically includes otherwise       |3           |0         |1.3862943611198906|\n",
      "|amazingness added rocked definitely minutes       |3           |0         |1.3862943611198906|\n",
      "|decided leave manager decided week                |3           |0         |1.3862943611198906|\n",
      "|stated uber instead cancelled thats               |3           |0         |1.3862943611198906|\n",
      "|smells including sparkling multitudes figurines   |3           |0         |1.3862943611198906|\n",
      "|either incredibly charming toes complete          |3           |0         |1.3862943611198906|\n",
      "|week surprised find birthday seated               |3           |0         |1.3862943611198906|\n",
      "|leave manager decided week work                   |3           |0         |1.3862943611198906|\n",
      "|reviews try give benefit doubt                    |3           |0         |1.3862943611198906|\n",
      "|gave voucher happened approximately careful       |3           |0         |1.3862943611198906|\n",
      "|manager decided week work workers                 |3           |0         |1.3862943611198906|\n",
      "|worse verbally assaulted upset give               |3           |0         |1.3862943611198906|\n",
      "|ordered appies appies porcini sachets             |3           |0         |1.3862943611198906|\n",
      "|including sparkling multitudes figurines customers|3           |0         |1.3862943611198906|\n",
      "|seated ordered appies appies porcini              |3           |0         |1.3862943611198906|\n",
      "|week decided leave manager decided                |3           |0         |1.3862943611198906|\n",
      "+--------------------------------------------------+------------+----------+------------------+\n",
      "only showing top 50 rows\n",
      "\n",
      "5-grams indicative of open stores:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6948:==================================================>   (41 + 3) / 44]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------+------------+----------+-------------------+\n",
      "|ngram                                              |closed_count|open_count|log_odds_ratio     |\n",
      "+---------------------------------------------------+------------+----------+-------------------+\n",
      "|frickin frickin frickin frickin frickin            |0           |301       |-5.71042701737487  |\n",
      "|lolol lolol lolol lolol lolol                      |0           |291       |-5.676753802268282 |\n",
      "|blah blah blah blah blah                           |0           |78        |-4.3694478524670215|\n",
      "|boner boner boner boner boner                      |0           |70        |-4.2626798770413155|\n",
      "|trying consistently towards visitors often         |1           |133       |-4.204692619390966 |\n",
      "|pacer meme deadthe pacer meme                      |0           |65        |-4.189654742026425 |\n",
      "|meme deadthe pacer meme deadthe                    |0           |65        |-4.189654742026425 |\n",
      "|deadthe pacer meme deadthe pacer                   |0           |64        |-4.174387269895637 |\n",
      "|welcomed felt loved shall definitely               |0           |60        |-4.110873864173311 |\n",
      "|prefere opportunity whenever need comes            |0           |54        |-4.007333185232471 |\n",
      "|rude rude rude rude rude                           |0           |53        |-3.9889840465642745|\n",
      "|deeply impressed handled correctly hassles         |0           |48        |-3.891820298110627 |\n",
      "|consistently towards customers frequently highly   |0           |47        |-3.871201010907891 |\n",
      "|work customer organized rates affordable           |0           |47        |-3.871201010907891 |\n",
      "|opportunity everytime need comes instantly         |0           |47        |-3.871201010907891 |\n",
      "|consistently towards clients often recommend       |5           |284       |-3.8607297110405954|\n",
      "|give consistently towards clients often            |0           |46        |-3.8501476017100584|\n",
      "|work customer kept rates reasonable                |0           |45        |-3.828641396489095 |\n",
      "|prepare consistently towards guests often          |0           |44        |-3.8066624897703196|\n",
      "|provide consistently towards clients often         |0           |44        |-3.8066624897703196|\n",
      "|horrible horrible horrible horrible horrible       |1           |87        |-3.784189633918261 |\n",
      "|give consistently towards customers often          |0           |42        |-3.7612001156935624|\n",
      "|trying towards customers often highly              |0           |42        |-3.7612001156935624|\n",
      "|provide consistently towards customers often       |0           |41        |-3.7376696182833684|\n",
      "|said said said said said                           |0           |41        |-3.7376696182833684|\n",
      "|towards customers frequently highly recommend      |0           |40        |-3.713572066704308 |\n",
      "|surely recommend convenient rates generous         |0           |40        |-3.713572066704308 |\n",
      "|enjoyed shall definitely highly recommend          |0           |39        |-3.6888794541139363|\n",
      "|work customer organized rates convenient           |0           |39        |-3.6888794541139363|\n",
      "|provide towards customers often recommend          |0           |36        |-3.6109179126442243|\n",
      "|trying consistently towards guests frequently      |0           |36        |-3.6109179126442243|\n",
      "|professional put shall surely highly               |0           |36        |-3.6109179126442243|\n",
      "|easily recommend convenient rates generous         |0           |36        |-3.6109179126442243|\n",
      "|nasty nasty nasty nasty nasty                      |0           |36        |-3.6109179126442243|\n",
      "|preferred places customer highly recommend         |0           |36        |-3.6109179126442243|\n",
      "|portions affordable consistently highly recommend  |0           |36        |-3.6109179126442243|\n",
      "|warmly welcomed members felt loved                 |0           |35        |-3.58351893845611  |\n",
      "|trying consistently towards customers frequently   |0           |34        |-3.5553480614894135|\n",
      "|consistently towards guests often highly           |3           |138       |-3.548179572010801 |\n",
      "|rates productive amiable highly recommend          |0           |33        |-3.5263605246161616|\n",
      "|opportunity everytime need comes straightaway      |0           |33        |-3.5263605246161616|\n",
      "|portions affordable regularly highly recommend     |0           |33        |-3.5263605246161616|\n",
      "|consistently towards guests frequently recommend   |1           |66        |-3.5115454388310208|\n",
      "|consistently towards visitors often highly         |3           |133       |-3.5115454388310208|\n",
      "|prepare trying consistently towards customers      |0           |32        |-3.4965075614664802|\n",
      "|consistently towards customers frequently recommend|1           |65        |-3.4965075614664802|\n",
      "|adore consistently towards visitors often          |0           |32        |-3.4965075614664802|\n",
      "|favourite rapidly rates definitely recommend       |0           |32        |-3.4965075614664802|\n",
      "|recommend trying delightful customer highly        |0           |32        |-3.4965075614664802|\n",
      "|opportunity everytime need decent comes            |0           |32        |-3.4965075614664802|\n",
      "+---------------------------------------------------+------------+----------+-------------------+\n",
      "only showing top 50 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# 4. Create 5-grams\n",
    "# ----------------------------\n",
    "five_grammer = NGram(n=5, inputCol=\"operational_tokens\", outputCol=\"five_grams\")\n",
    "closed_df = five_grammer.transform(closed_df)\n",
    "open_df   = five_grammer.transform(open_df)\n",
    "\n",
    "# ----------------------------\n",
    "# 5. Explode 5-grams and count\n",
    "# ----------------------------\n",
    "def five_gram_count(df, count_col):\n",
    "    return df.select(F.explode(\"five_grams\").alias(\"ngram\")) \\\n",
    "             .groupBy(\"ngram\").count().withColumnRenamed(\"count\", count_col)\n",
    "\n",
    "closed_counts = five_gram_count(closed_df, \"closed_count\")\n",
    "open_counts   = five_gram_count(open_df, \"open_count\")\n",
    "\n",
    "# ----------------------------\n",
    "# 6. Combine counts and compute log-odds\n",
    "# ----------------------------\n",
    "combined_counts = closed_counts.join(open_counts, on=\"ngram\", how=\"outer\").fillna(0)\n",
    "combined_counts = combined_counts.withColumn(\n",
    "    \"log_odds_ratio\",\n",
    "    F.log((F.col(\"closed_count\")+1) / (F.col(\"open_count\")+1))\n",
    ")\n",
    "\n",
    "# ----------------------------\n",
    "# 7. Rank for comparative insight\n",
    "# ----------------------------\n",
    "top_closed_5_grams = combined_counts.orderBy(F.col(\"log_odds_ratio\").desc())\n",
    "top_open_5_grams   = combined_counts.orderBy(F.col(\"log_odds_ratio\").asc())\n",
    "\n",
    "# ----------------------------\n",
    "# 8. Show top results\n",
    "# ----------------------------\n",
    "print(\"5-grams indicative of closed stores:\")\n",
    "top_closed_5_grams.show(50, truncate=False)\n",
    "\n",
    "print(\"5-grams indicative of open stores:\")\n",
    "top_open_5_grams.show(50, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81bcfae-bbdf-4c4b-9884-4381c3346deb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
